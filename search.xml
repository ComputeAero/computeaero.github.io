<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>《科学需要讲故事》</title>
    <url>/2020/04/26/science-narrative/</url>
    <content><![CDATA[<pre><code>                                    **简单是复杂的最终形式--达芬奇**
</code></pre><p>我们都知道当前的非洲是相对落后的，每年有不少人死于因贫穷导致的各种问题中，然而如果有2个人分别跑来告诉你以下的2句话，哪句话更能让你产生强烈的感触？<br>1.在非洲东部的一个小村庄里，一个9岁的小女孩因为家庭贫困导致的营养不良，患上了一种奇怪的病，导致神经系统萎缩，最后在痛苦中死去了。<br>2.在非洲，每年有超过100万个未成年人因营养不良而死亡。</p>
<p>很明显，第1句更能触动听众，因为它能让听众产生更加强烈的切身痛苦，尽管第二句里的死亡人数是第一句里的100万倍。上面2句话的最大区别在于，一个是叙述一件事，另一个是呈现一件事实。当人们听到一个具体的故事时，往往能产生代入感，让自己感同身受。但是如果是一个干巴巴的事实呈现在人们面前，人们会产生“这件事跟我有什么关系？”这样的感受。因此，传达一个信息的方式，甚至比这个信息本身，更能影响它在人群中产生的影响大小。</p>
<p>本书的作者兰迪-奥尔森（美），本来是一名已经拿到终身教职的生物科学家，拥有一份非常稳定，福利超好且受人尊敬的工作，但是在38岁那年辞去了大学的教职，转而去了好莱坞进修电影制作的课程，在那个过程中，以电影为基础，他不断学习和思考了如何把“传播”这门艺术用在科学上，因此就有了这本书。<br><a id="more"></a><br>做过自然科学研究的人，都知道科学的传播依靠的是论文，学术报告，研讨会，科普演讲等等，以上活动在地球上每时每刻都在发生着，但是因为科学往往是复杂和深奥的，所以各种形式的科学传播基本上都在罗列各种事实，用了各种and….and….and式的句子（书中称AAA结构）或者despite…however…yet（书中称DHY结构）。因此听众往往在听5分钟后就要么因为AAA的枯燥而昏昏欲睡，要么是因为DHY的多次转折而不知所云，即便最后学到了一部分知识，在之后的几天之内就会全忘光，从而导致这种类型的科学传播的效率很低。然而，于此相反的一个现象是人们往往能坐在电影院里津津有味地看2小时的电影，并且在那之后相当长的一段时间里，都对里面的某些情节记忆犹新。电影和学术报告的最关键的区别就是，前者在给观众讲述一个完整的故事，而后者在给听众罗列枯燥的事实或呈现复杂的线团。人们能听进去几条事实，但是不会听进去太多。但是他们会毫无怨言地不停地听人讲述漫长的故事。这就是人脑的程序性缺陷，这就是叙事的力量。</p>
<p>好了，那么接下来我们的目标就是：把科学的传播变成讲故事。但是肯定会有人说：“我们写科学论文，是有一套固定的模式的，introduction-method-results-discussion-conclusion，虽然不甚吸引人，但是至少让人很容易掌握，但是从古至今的故事并没有特定的模式，如果要求科学家去学习如何讲故事，那肯定会花费巨量的时间和精力，哪还有时间做研究？”这个问题，作者在书中引用了人类学家约瑟夫坎贝尔在1949年出版的《千面英雄》，这本书通过考察在人类历史上大量的神话和宗教故事，最后寻找了一个单一的共同的故事结构。也就是说，所有的故事都是一样的。或者说，所有的故事都是一个结构：(…and…but…therefore….)ABT，而非AAA或DHY. 说白了就是现在我们处于一个现状and另一个现状，但是我们有了一个困难…，因此我们需要做…来解决困难。就是这样一个简单的ABT，构筑起了人类历史上所有的故事。ABT足够复杂，因为里面包含一个冲突，但又足够简单，因为没有九曲十八弯的复杂线索。比如：<br>1.过去8000年海平面已经稳定了And人类文明就这样建立在海岸边缘上，But过去150年海平面急速上升，Therefore现在是时候重新调整沿海区域规划了。<br>2.海平面上升是人类活动的结果And我们真的需要削减温室气体排放来阻止海平面上升，But事情已经到了无法挽回的地步，无论我们做什么，海平面还是会有所上升，Therefore我们需要学会平静接受的同时，也需要对此做出行动来减缓其上升的程度。</p>
<p>ABT解决的是从微观层面的写法，对于更大规模的安排，这里可以参考电影的原始情节设计原则来参考：<br>1.线性时间线： 如果你讲的事件在时间上发生跳跃，你就开始失去听众<br>2.因果性：如果你讲的事件之间没有清晰的因果关系，你就开始失去听众<br>3.单个的主角： 一旦开始同时讲好几个项目，而不仅仅聚焦在一个项目上，你就开始失去听众<br>4.活跃的主角：一旦开始讲故事中的内在冲突（我们在思考是否应该做这个实验），而不是讲外部冲突（做了实验，发现有个恶果），你就开始失去听众<br>5.封闭式结局：如果你的故事最后没有解答前面出现的全部的问题，你就开始失去听众</p>
<p>从作者兰迪的坦言中，我也找到了些许共鸣。作者兰迪说身为理工科学生，在大学几乎没有读过人文类课程。即便他的一位好友在允许学生自己设计课程体系的布朗大学，那些想成为科学家的学生，几乎都单刀直入地选择了大量的自然科学课程，极少有人进行过系统的人文科学训练。我觉得这一点在发展中国家，比如中国，的学生身上应该更加明显。以我为例，高中二年级就开始文理分科，而且事实上，在高中一年级的时候，学生们就几乎在心里给自己分了文理科。我本科就读的大学也是一所以理工类为主导的大学，虽然也有外语系，法律系和艺术系，但是存在感非常低。平时的讲座也大多是理工类的科普讲座（形式以AAA结构为主），但是其实作者指出真正的教育必须是全方位的，是以人性为基础的，目前的这种教育太过于关注具体的技术，太过功利了，对个人乃至人类的长期发展极为不利。自然科学家不应该是一个从外部接收真理的机器，自然科学家应该是从特定文化背景种生长起来的有人性的个体，有优点，同时也有缺点。因此，只有通过人文精神的培养，才能让他们充分认识自己和认识所从事的伟大事业，而不仅仅是发论文，申请基金或开公司赚钱。正如著名的生物学家斯蒂芬-杰伊-古尔德的一个观点就是“如果你能理解科学家的人性弱点，就无法理解科学家，那些渴望讲述大故事的科学家可能是最伟大的人”。</p>
<p>其实在写这篇总结的时候，我刻意在强迫自己使用ABT结构，感觉读起来通畅了许多。最后分享个资源，正好前几天看到了去年教育部印发的《2019年全国中小学图书馆（室）推荐书目》，一个400多页的PDF文档，共推荐了6905本书。发现这本《科学需要讲故事》恰好是书目列表里的最后一本，也算是有幸读到了这本“收官之作”。推荐书目见链接: <a href="https://gofile.io/?c=ZyqX76" target="_blank" rel="noopener">Link</a></p>
]]></content>
  </entry>
  <entry>
    <title>《给仰望者的天文朝圣之旅》Note</title>
    <url>/2020/04/19/yangwang/</url>
    <content><![CDATA[<p>最近读了切特莫雷（Chet Raymo）的《给仰望者的天文朝圣之旅》，这本书的写法跟之前所有的科普书都不一样，故事是从作者在波士顿的一个街区看到一个年轻人滑着滑板撞了一个小女孩开始的，在那一瞬间，作者联想到用天文望远镜观看在宇宙中的恒星爆炸的场面，由此展开了作者对星空的一系列相关的经历和思考。在介绍某一个宇宙空间的概念之前，都会从身边的亲身经历开始，比如小孩被撞倒的一瞬间，周围环境的寂静，联想到了宇宙中因为接近真空而表现出的寂静；还有从自己小时候置身于黑色的松林之中，仰头寻找星夜中的小斑点，过渡到希腊神话中的猎户座在黑暗中的勇猛向前，从而引发了关于光明和黑暗的一系列探讨。正如约翰巴勒斯的那句“了解只是其中一半，而爱是另一半”，字里行间，能感受到作者对世间万物的了解和爱。</p>
<p>在宇宙的世界里，距离都是用光年来计量的，当我们离开地球，任何一次与外太空的接触都将耗费巨大的人力物力和时间才能完成，所以让人遥不可及。但是作者总是能找到一个最贴近我们的东西来证明宇宙的历史对我们来说非常紧密，我们随时可以把宇宙拉到自己身边。比如我们写字用的铅笔中的石墨，其中的每一个碳原子，都是宇宙早期核聚变的产物，都贴着“金牛座制造”或者“猎户座制造”的标签。而且，我们身体里的每一个原子都是经过恒星的锻造，才组成现在的人类社会，所以我们自己跟宇宙的源头息息相关。<br><a id="more"></a></p>
<p>宇宙不是冰冷的实物，而是一曲和谐的乐章。在过去相当长的一段时间，物质的经典概念就是形态为固体且具有质量的物体，就想组成沙滩的沙子一样，比如中学的时候，我会把原子和电子想象成像太阳系一样的系统，电子围绕着原子核在匀速旋转。但是随着量子力学的出现，在原子的尺度上，物质跟能量其实可以相互转化，物质不再是一种实体，而更像是一种虚空的存在，然后从那以后，“物理学家开始用作曲家的语言来描绘原子—“共振”“频率”“和谐”“级”。物质和光之间的典型区别变得模糊不清。在新物理学里，光可以像粒子一样反弹，物质也可以像光一样产生波的涟漪”。当时看到这一段时，确实被这样的事实震撼到了，在近代物理诞生之前，音乐作为一门艺术就已经存在了很长时间了，音乐家们用自己的一生去谱写去演奏的东西，曾经用于鼓舞人心、批判丑恶、揭露现实、赞美美德的东西，经过千年的积累，现在被完全用于描述物理学的微观世界，这是多么震撼的艺术家与科学家之间的“接力”！这让我联想到了数学，起初的数学确实是属于纯粹思维上的玩物，在微积分发明之后，被迅速用于描述大自然的方式，从而极大地拓展了我们的认识。读完这本书最大的收获其实在于明白了我们所有一切的思想活动，都是在直接或间接地拓展着我们认识世界的工具，就像从最初的木棍，再到青铜器，再到铁器，最后到无所不能的瑞士军刀一样。</p>
<p>那么面对如此宏大的宇宙，我们该怎么开始呢？作者在其中提到了科学家通过观测银河系中遥远天体的运动速度，可以计算出束缚他们的总质量，从而发现银河系中97%的物质还没有被探测到，这些物质被统称为暗物质。看来宇宙中的绝大多数真相被隐藏在角落里，约翰巴勒斯说：“如果世界永远以一种赤裸裸的宏伟姿态出现，也许会超出我们的承受能力。但无限的一半仍然是无限，一点点的无限，也是无限的—如果我们能抓住那一点点的话。这里有一条线索，那里有一条暗示，线索和暗示组成了我们前进的道路。”其实这句话，让我联想到了胡适的那句“怕什么真理无穷，进一寸有一寸的欢喜”，只要抓住自己感兴趣的那一点线索往前走，就会看到别人看不到的东西。</p>
<p>最后说几个觉得有意思的段落：</p>
<p>现存最古老的星图是由中国天文学家石申和甘德在公元前4世纪编制的。但是中国古人不是以现代天文学的眼光来研究星星的，他们的目的是从夜空中看到自然秩序，然后以此为基础来达到稳固其社会秩序以及与个人生活相融合的目的，难怪中国古代有那么多描写星空的诗句，因为在当时的人心里，已经把星空和自己融合在了一起。跟之前看《从一到无穷大》里面说第一次对超新星爆发的记载也出自中国一样，中国古代对自然科学的认识是很早的，只是由于阴差阳错，没能发展出一套科学的体系。</p>
<p>全书最让人哑然失笑的地方，在聊到北斗七星的时候，西方把北斗七星叫大熊座，但是看上去并不像熊，作者还考察了北斗七星在历史上的各个时期的样子，发现并不像熊的样子，在百思不得其解之后，作者得出了另外一种可能性：也许在某个历史时期的熊长得像勺子。</p>
<p>最后我发现了本书里几处跟刘慈欣小说《带上她的眼睛》很类似的描写，比如<br>本书里“铁匠赫菲斯托斯为众神锻造了金色的太阳和银色的月亮”<br>跟《带上她的眼睛》：“我想象着金色的阳光和银色的月光透射到这个星球的中心”<br>用了相同的描写。喜欢刘慈欣作品的原因也正是他能把宇宙和人心紧密地结合在一起，所以个人猜测刘慈欣从这本书里吸收到了很多东西，并且从我个人的感受来说，刘慈欣写得更加自然，而这本书里面虽然旁征博引，但是有时候这种联系跨度太大，难以在脑海中建立直接的联系，显得比较牵强，所以我对这本书打4.5/5星，四舍五入，5星。</p>
]]></content>
  </entry>
  <entry>
    <title>《枪炮，病菌与钢铁：人类社会的命运》Note</title>
    <url>/2020/03/19/gun-steel-virus/</url>
    <content><![CDATA[<p>最近COVID-19新型冠状病毒在全球肆虐，病毒刚刚在中国被控制住，又开始在欧洲大规模爆发。目前的医学水平还尚不能针对这种病毒进行专门的医治，也就是说没有特效药。所以，目前临床上只能采取一些生命维持的常规手段来辅助病人的免疫系统来抵抗病毒。在预防方面，疫苗的研发也不是立刻就能投入市场的，而是需要大量的跟踪试验，在确保副作用可控的前提下，才能投入市场，所以现在的医学发展水平还远未达到能够让我们沾沾自喜的程度。虽然我们有观察宇宙的射电望远镜，有飞出了太阳系的旅行者号探测器，有昼夜围绕地球的通信卫星，但是当我们面对像病毒这类及其微观的东西的时候，显得非常乏力。而且先撇开病毒，即便是对单个蛋白质这类的有机大分子而言， 我们要想对它有所认识，也非常困难。之前看到过一个超级计算中心的项目比例，生物蛋白质这方面的分子动力学模拟占了该超算中心全年算力的50%以上，可见想认识这样的东西需要耗费多少时间，精力和资源了。这让我产生了一个好奇：“既然人类被这么多病毒环绕着，在如此艰难的环境下为什么依旧能坚持走到今天？” </p>
<p>正好在之前读了一本有关的书，叫<strong>《枪炮，病菌与钢铁：人类社会的命运》</strong>（简称《枪炮》）。作者是美国生物演化学家贾雷德·戴蒙德。最开始是在时代周刊评选出的100本非虚构类书籍列表里找到的。其实上面的那个好奇的问题非常宏大，人类的历史里肯定是充满了各种各样的因素，有自然界的因素，有人为的因素，也有很多偶然但非常具有决定性的因素等等，这些因素绝不可能通过一两本书就解释清楚。这本《枪炮》选择了从人类生存的自然环境这个角度来诠释人类的发展，从远古人类走出非洲开始，一直讲到现存的主要地区和国家（欧美，非洲，中东，太平洋群岛，澳洲，中国，日本）形成的格局，基本上除了南极的企鹅没有被涉及到，其余的地区都有讲到。 虽然这本书获得了英国科普书奖，但是我觉得这里面的很多内容，跟专业的文献资料非常相像：事无巨细地摆出所有证据，并且加以非常严密的逻辑分析， 从而得出结论。这种“学院派”的书也确实有一个缺点，那就是很多地方是大段大段的考古发现和错综复杂的论证线条，具有非常好的催眠作用。所以每天睡前看几页，就成了当晚睡眠质量的保障。<br><a id="more"></a><br>这本书源自作者的一个新几内亚的朋友耶利提出的问题：“为什么你们白人制造了这么多货物并且将它们运到新几内亚，而我们黑人却几乎没有属于我们自己的货物呢？”。这个问题也以引申出很多类似的问题，比如说“为什么现在世界上通用语言是英语，而不是汉语，法语，日语等等？”“为什么现代科学研究的中心发源自欧洲，而不是非洲，亚洲，大洋洲，美洲？”。这些问题可以归结为一个总的问题：“为什么地球上不同地区目前处于不同的发展阶段？” 这个问题确实非常宏大，任何理论分析也无法完完整整地将它解释清楚，但是作者给出了一个确切的答案：“不同民族的历史遵循不同的道路前进，其原因是民族环境的差异，而不是民族自身在生物学上的差异。”可见作者把外部环境作为了这本书的核心，如果让我来概括这本书的话，那就是在一个前提（人类从非洲起源）下，N种自然环境决定了N个族群（民族）的历史，最后形成目前的世界格局。在第一次读这本书时候，因为里面充满了很多不熟悉的地名人名和历史， 虽然一边惊叹作者知识的广博，其实我是非常懵的，在跟着作者读完全书后，就试图想如果把这个宏大的问题通过具体化来缩小到一个更加小的问题上，也许会更容易去理解。比如说， 同样的一本书，为什么不同的读者会产生不一样的理解？对一个情节的理解的深度也不尽相同？按照作者的意图来说，答案应该就是不同的读者有不同的生活环境，从而产生不同的生活阅历和不同的思考方式，从而导致对同一本书产生各种各样的理解。</p>
<p>全书内容非常丰富，说一个最让我记忆深刻的部分：为什么是欧洲殖民者征服了美洲而不是反过来。作者给出的原因除了更加先进的铁制武器和更加高效的农业种植技术养活了更多的人口外，就是病毒。从欧洲来的人携带了很多在美洲从未出现过的致命病毒：天花、麻疹、流行性感冒、白喉、疟疾、腮腺炎、百日咳、黄热病等等。这些病毒让印第安人减少了95%，远比通过枪炮杀死的人多。但是这个这个答案显然不够深刻，因为既然欧洲人带来了欧洲的病毒，那么美洲的原住民也会把美洲的病毒传给欧洲人，为什么美洲的病毒没有威胁到欧洲殖民者呢？作者的答案是：病毒的来源都是从人类驯养的动物身上通过变异，从而传染给人类的。因为欧洲人驯化了大量的牲畜，而在美洲，驯化的牲畜极端匮乏，只有5种：火鸡，羊驼，豚鼠，家鸭和狗。这些动物要么是本身就很少携带病毒，要么是跟人类接触不多，总之难以产生大量的致命病毒。显然，这个问题还可以继续追问下去：为什么欧洲驯化的动物比美洲的多？作者给出的解释是2个原因：1、欧亚大陆由于其广大的面积和生态的多样性，本来就拥有最多的可供驯化的候选动物。2、因为欧亚大陆的人和动物都是在同一个环境下同步进化的，随着人的狩猎技术的提高，动物也在跟着进化（速度更快，嗅觉更灵敏等等），所以不至于被人类的灭绝。但是因为美洲的原住民是通过亚洲大陆过去的，当时的人类的狩猎技术已经提高了很多，而美洲的动物之前并没有经历过人类的捕杀，所以很快就被人类通过捕猎而灭绝。读完这本书，最大的感受就是，如果非洲跟美洲之间连着，那么现在历史就全要重写，就这么简单。</p>
<p>读完这样一本宏大的书，其实内心并没有太多波澜，因为所有一切的论述都是那么严丝合缝，用一个流行词来形容就是“理中客”，人类几万年的进化和发展，被打包进1个假设+N种环境这种框架下，感觉人类的历史不过是一条沿着山脊顺流而下的小溪。一切都规划好了，这是我想看到的历史吗？ 我想看到的是夸父追日，孔子老子，万里长城，阿基米德，高斯牛顿这些活生生的人，是他们创造了历史，而不是那些客观存在的气候和地理。作者其实也承认只有人类的智慧才能发明农业，驯化动物，发现青霉素，冶炼青铜器和铁器，从而创造出我们现在拥有的一切。看来整整一本书，只把耶利的问题回答了50%。最后作者再次强调了不支持“欧洲中心论”这种充满种族主义的观点，这本书只是论证了各个文明形成的原因，而不是对现状作道德判断。事实上，欧洲目前的文明也是从很多其他地方传入后，经过消化吸收，演变成了现在的样子。我也一直觉得，文明的发展就像基因突变，没有明确的目的，而且有非常大的偶然性，只有文明的数量够多，才能在未来更有可能出现一些“好”的文明。如果我们无限制地吹捧某一种文化，而排斥其他文化，那么势必会减少我们更上一个台阶的可能性，而这种可能性蕴藏着最终的某种必然性。</p>
]]></content>
  </entry>
  <entry>
    <title>《张纯如：无法忘却历史的女子》Note</title>
    <url>/2020/02/09/zhang-chunru/</url>
    <content><![CDATA[<p>带着感动读完了这本书。张纯如，一个普通的美国华裔，凭借自己的那一份执着，用了3年的时间，跑遍了美国和德国的图书馆，采访了中国的南京大屠杀幸存者，联系到了拉贝的后人。通过自己的努力，把1937年日军在南京所犯下的罪行在英语世界第一次完整地系统地呈现出来，仅仅凭借一个人的力量，跟一大群试图掩盖真相的人针锋相对。当凭借《南京大屠杀》声名鹊起后，却在2004年在深受抑郁症折磨下，选择了自杀。其实，在读这本书以前，一直觉得一个个人能做的事情很有限，选择一件事情，然后埋头坐下去，最后通过自己的一点点努力，在这个世界的汪洋大海中，挑起一个小的涟漪，让这个世界变好那么一点点。但是读完这本书，发现原来人生还可以是另外一翻模样：不问结果地追求一个认定的东西，在惊涛骇浪中荣辱不惊。</p>
<p>其实在读完《南京大屠杀》之后，我就对张纯如本人产生了强烈的好奇，好奇是什么因素造就了一位内心如此强大的人？她的童年和少年时期是怎样度过的？是什么原因促使她会选择写《南京大屠杀》这样一部著作？最后到底是不是因为见到了太多人性的阴暗面或者受到太多右翼人士的威胁和攻击而让她产生轻生的念头？这本书是张纯如的母亲张盈盈女士耗时6年于2011年出版的书，记录了张盈盈从出生，上学，新闻媒体实习，再到成为自由作家，以及后来因为抑郁症而自杀的全过程。我在上面列出的所有问题，都在这本书里得到了解答。非常感谢这样一位同样伟大的女士－－张盈盈，正是因为有了她的这本书，让我看到了一个活生生的张纯如：竟是如此的可爱和可敬。<br><a id="more"></a></p>
<p>下面是自己认为比较重要的时间表：<br>1968年3月28日，张纯如出生于新泽西州的普林斯顿医院。<br>1970年9月24日，张纯如的弟弟纯恺出生。<br>1973年3月28日，生日当天，家里举办了姜饼屋生日派对。<br>1973年秋天，每周六，开始上中文学校，写繁体字，但是学大陆的汉语拼音<br>1974年，在厄巴纳杨基岭读小学<br>1975年，因为纯如长得漂亮，经常受到夸赞<br>1975年，喜欢读爱丽丝漫游奇境记<br>1976年，爷爷奶奶也搬到了美国，看国庆烟花表演<br>1977年，在课堂上展示中国的春节文化<br>1977年，开始养蚕（第一本书《蚕丝》的名字也许来自此处）<br>1978年，开始自己写故事和诗，自封为作者；开始养猫，给猫取名“Cat” ；短篇小说《老鼠一家》在小学获奖；跟同学办小报<br>1979年，小诗发表在《那个报》的试刊号上<br>1980年，自制贺卡，并且祝福母亲生日快乐；向父母打听中国在二战时期的遭遇；升入伊利诺伊大学实验中学<br>1981年，因为大量读书，视力下降，开始带隐形眼镜<br>1982年，因为爸爸学术休假，去台湾的中学短期读书；回到美国后，想把一个停刊的《特立独行》复刊；想加入一个计算机俱乐部，但是俱乐部以她是女性为由拒绝了她<br>1983年，学习Pascal语言；参加医院的志愿者社团“彩条糖”；加入伊利诺伊大学校园的计算机工程研究实验室（CERL），参与PLATO工作；写了2首小诗《肥皂泡》《日出》<br>对科幻小说的热爱，读了《时间机器》《世界大战》《2001：太空奥德赛》，跟克拉克保持通信；读了科普书《从一到无穷大》《生命是什么》<br>1984年，备考SAT考试，准备考大学；夏天全家旅行，横跨半个美国<br>1985年，拿到了驾照，交了很多文友，爸妈参加毕业舞会；选择了2个最欣赏的名人名言，分别是文学家马修阿诺德的“诗是描述食物最美丽，最动人，最老幼皆宜的一种方式，他的重要性正是由此而来”和爱因斯坦的“想象力比知识更重要”<br>1985年夏季，入学伊利诺伊大学，攻读数学和计算机双学位<br>1986年，修《抽象代数》课程，开始怀疑人生（在这一点上，我跟纯如找到了共鸣！）<br>1987年夏天，在芝加哥的Microsystems公司暑期实习，每周工作40小时，报酬是400美元；大三转入新闻系；10月12日为《伊利诺伊人日报》写第一篇文章“跳跳糖：真好玩，还是真要命？”；11月6日，发表“惠特尼休斯顿将听众的人情引向新的高度”<br>1988年，发表“神秘崇拜者”；入选美国杂志编辑协会的暑期实习项目，分配到《新闻周刊》实习；经常往《纽约时报》投稿伊利诺伊大学的校园新闻并被采纳；成为了“返校节宫廷”的皇后<br>1989年，获得美联社芝加哥分社的实习机会，转到《芝加哥论坛报》实习，写了《科学家眼中的爱因斯坦，公众眼中的那谁谁》（主人公是二度获诺贝尔奖的巴丁教授）<br>1990年，没有被《芝加哥论坛报》续约，所以回到了伊利诺伊老家；跟布瑞特订婚<br>1991年，在编辑苏珊的建议下，开始写一本有关钱学森的书<br>1992年，得到凯瑟琳`麦克阿瑟的基金会15，000美元的研究经费，参加世界太空大会，联系到了中国的太空科学家<br>1993年，飞到中国，造访了杭州，上海和北京，搜集资料<br>1994年，在台湾，杨振宁向纯如的父母打听纯如写的有关钱学森的书的情况；10月18日，写完了《蚕丝》；12月13日，参加加州库比蒂诺会议，看到了南京大屠杀的照片<br>1995年，因为《蚕丝》，被nature和science报道，举行签售会<br>1996年，写《南京大屠杀》，联系到了拉贝的外孙女，被拉贝日记所震撼，下决心要写好<br>1997年，《南京大屠杀》登上了纽约时报畅销榜，接受采访，<br>1998年，和日本驻日大使电视辩论，跟希拉里见面，“这些修正主义者正在进行第二次南京大屠杀－－对历史的屠杀”<br>1999年，开始写《美国华人》<br>2000年，无法怀孕，为南京大屠杀的改编电影奔走失败<br>2001年，使用代孕技术；参加了有关日本的历史活动<br>2002年，孩子克里斯托弗出生<br>2003年，为《纽约时报》写了SARS文章，开始构思下一本书，有关巴丹死亡行军<br>2004年，怀疑克里斯托弗有自闭症，纯如四处寻找药物；自己开始出现精神病症状，服用药物，效果不好，反复更换医生，最后11月9日，自杀</p>
<p>纯如有一句话特别有味道：<br><strong>“首先，请你务必，务必，务必相信一个人的力量。一个人可以令世界大为改观。一个人，事实上，一个想法可以发动一场战争，或者是结束一场战争，或是颠覆整个权力结构。一个发现可以治愈一种疾病，一种新的技术可以造福或毁灭人类。你是一个人，你可以改变数百万人的生活。志存高远，不要限制住你的目光，永远不要放弃你的梦想或理念……”</strong></p>
<p>读完这本书，除了悲痛之外，更多的是鼓舞，因为每个人都有离开的那一天，无数的快乐和悲痛都会沿着时间之光的方向远去，但如果能做到为一个梦想而一直坚持着，那么远去的光也肯定是温热的</p>
]]></content>
  </entry>
  <entry>
    <title>《从一到无穷大》Note</title>
    <url>/2020/01/18/one-to-infinity/</url>
    <content><![CDATA[<p>如果要问哪一本书能把我之前对时空的很零星的很多疑惑一次性解答的话，那么这本G.伽莫夫的《从一到无穷大》肯定名列前茅。看到书名的时候，还以为里面会讲数学意义上的从小到大，翻开后果然没猜错，确实是从“指数级增长”开始的（这个词在互联网创业者里很流行），但是立刻就从思维层面的从小到大，引申到了物理世界。从非生物的夸克、原子、分子，进化到了到了有生命现象的病毒、细胞，再到包括一切的行星、恒星、星系，最后到宇宙，完成一次从极小到极大的穿梭。这本书里既有作者精心的解释，也讲了很多为了某些问题而探索的勇敢的科学家们的故事。这里之所以用“勇敢”来形容他们，就是因为其实很多真理是从一堆错误的猜想中一步一步筛选和修改而来的，很多科学家在自己所提出的理论上探索了一生，最后也只能是帮助后人排除一种错误选项，而这样的现象其实正是科学史上的常态。写个Note，说说其中最让我感到“学到知识的虚荣感”的一段吧，它就是弯曲的三维空间。</p>
<p>弯曲的一维空间，很容易想象就是一根曲线。弯曲的二维空间，也很容易想象就是一个曲面，但是弯曲的三维空间却非常困难，因为我们“身在此山中”。一个生活在三维空间中的“三维人”要想理解自己所处的空间，可以想象一个生活在二维弯曲空间的“二维人”对二维空间的理解。可以想到，在球面上，三角形的内角和并不等于180度（比如，连接赤道上2点和极点的三角形的内角和可以是任何值），所以这个“二维人”就会认为自己所处的空间（其实就是一个二维球面）是弯曲的。这里可能会有人质疑：“三角形的三条边必须是直线才叫三角形，而连接极点和赤道点的线明明是曲线，怎么成了三角形了？” 其实这个问题也是我的疑惑，但是作者已经预料到了这个很经典的问题，解答是：因为我们是3维生物，才能发现那个线是直线，对于二维生物而言，它就是直线。<strong>因为直线的定义是：两点之间最短的线，且这条线必须契合它所在的空间。</strong>所以对于生活在球面上的二维生物来说，连接极点和赤道上点的线，就是在这个二维空间上2点之间最短的线。而我们想象的那条连接2个点且穿过球体内部的直线，恰恰是三维空间下2个点的最短距离。<br><a id="more"></a></p>
<p>回到刚才的问题，如何判断我们所处的三维空间是不是弯曲的？我们也可以测量三角形的内角和来确认所处空间是不是弯曲的，但是可惜的是，现实中能找到的距离很远的3个点距离还是太近了（比如取围绕喜马拉雅山的3各点），不管怎么测量，都是180度。就像在地球这个球体上取一个很小的地方，那么看上去就是一个绝对的平面。这也正是在古代，为什么不管全世界哪里的人们都会认为大地是平坦的的原因。所以要想搞清楚这个问题，必须离开地球，仰头看向星空。这时候相对论就帮上忙了，爱因斯坦认为大质量物体周围会导致空间弯曲，所以在有无太阳的情况下，2个恒星之间的视线夹角会有所不同。夜晚，天空中的星星很好观察，但是在白天（有太阳）的情况下，因为阳光太亮，天上的星星根本看不见。这个时候，人们想到了一个绝美的点子，那就是在白天唯一可以看见星星的时候就是日全食的时候。所以一支英国的小分队在1919年的时候专门去了西非的普林西比岛上利用日全食的时候，能看到星星，才测量到了这种角度的微弱变化，为1.5”左右，证明了我们所处的空间确实是弯曲的。</p>
<p>其实这本书里还有很多让我为之一惊的瞬间，比如：</p>
<ol>
<li>最后印象最深刻的是法国的物理学家－斐索用短距离测量光速的实验，用2个齿轮就精确测出了光速是每秒30万千米，实验的设计之巧妙，让我觉得实验物理学家都是创意大师。</li>
<li>最令我大跌眼镜的是，空气中分子热运动的速度其实有每秒钟几百米那么快，也就是说他们虽然被周围的分子压缩在一个很小的尺度上快速来回撞击（每秒一万亿次），但是如果把这个速度“摊平”，已经是超越音速了！</li>
<li>让我不禁失笑的一段是有关第二类永动机的。我们都知道，热能永远无法全部转换成机械能，也就是说分子热运动所包含的能量，无法全部用来对外做功，也就是内燃机的效率不可能达到100%的原因。事实上内燃机的效率一般也就不超过40%，这也就是为什么电动车如此诱人的原因，因为电动机的效率可以达到80%以上。言规正传，但是书里面提到了，如果我们谈论的主体不是宏观的内燃机或电动机，而是是分子，或者比分子大一点的细菌，结论还成立吗？这个问题很有趣，刚开始确实把我问住了。因为我们所定义的内能，其实就是分子的热运动。热运动也是一种运动！也就是说对于分子或细菌而言，热运动跟它所的具备的机械能之间，其实就是一回事！所以，作者说:”对于那些一辈子都被周围分子推来搡去的细菌，当然会对“热无法完全转换成机械运动”的观点嗤之以鼻”。这一段着实把我逗乐了。</li>
<li>最让我意外的是里面提到一次很早的超新星爆发的记录是来自中国的文献的。因为这种超新星爆发非常罕见，大约500年才来一次，早在1054年的宋朝，正好赶上一次超新星爆发，并且记录了下来。身为中国人，居然是从一本外国人写的科普书的中译本里才知道这个事实，百感交集。后来又查了一下，世界上最早的超新星爆发记录是什么，意外地发现，居然也是来自中国的文献。它在公元185年，中国的天文学家就记下来有一个“客星”在天空中持续了8个月之久。公元185年，是东汉末期那一段动荡的时期，汉献帝命董卓为中郎将，讨伐黄巾军。在这种乱世中，中国的天文学家把超新星爆发记录了下来。《后汉书·卷十二·天文下》：“中平二年十月癸亥，客星出南门中，大如半筵，五色喜怒稍小，至后年六月消。占曰：‘为兵。’至六年，司隶校尉袁绍诛灭中官，大将军部曲将吴匡攻杀车骑将军何苗，死者数千人。”<br>看来星空之下，没有国籍。</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>Vectorization I</title>
    <url>/2019/05/12/parallel-cpu-coursera/</url>
    <content><![CDATA[<p><strong>Q: Recently, I saw many new product launching presentations of smart phones. To run those bigger and bigger mobile video games, the mobile phones are gettting faster and faster.</strong><br>A: Exactly. However, I want to say although smart phones are upgraded to cater to the emerging apps, many apps are far from exploiting all the hardware resources yet.<br><strong>Q: Really? Doesn’t the mobile apps run always faster on more recent devices?</strong><br>A: Not always. Actually it may be slower in most cases.<br><strong>Q: Oh? Why? The CPUs are faster and faster, right?</strong><br>A: No, not that case. See this figure. The CPU’s frequency has stagnated for around 10 years. However, the number transistors and logical cores are increasing rapidly, which lead to the speedup of microprocessors.<br><strong>Q: Hmm… I don’t know much details about these parameters, but why the frequency can not be improved evidently?</strong><br>A: It relates to a lot of physics. To make it short, the power cost will increase exponentially with the increasing clock speed. Also, as a result, the generated heat can not be handled by the cooling system. It will burn. This is the reason why vendors are turnning to multi-core strategy.<br><strong>Q: Hmm… I see. Let’s dot try to improve the clock speed. But I think if an computer or smartphone has more cores, the apps should be faster than running on a single core, because we have more workers, right?</strong><br>A: Not the case by nature. Let me first say the “frequency”. The frequency is a free lunch for developers, because it determines the execution speed of each instruction, thus programmers don’t need to pay any special attention on it. It means that, on a 1GHz processor, a program can run 10 times faster than that on a 100MHz one without any change of the code. However, a program can not exploit the multi-cores automatically, because the original program was designed to run on a single core. While it is running, other cores are just idle there. To use the power of multi-cores is the work of programmers.<br><a id="more"></a><br><strong>Q: So… programmers, nowadays, have to manipulate the multi-core hardware directly while programming? That will be very difficult.</strong><br>A: No. If that’s the case, most of programmers will be laid off, because that will be a very steep learning curve. Also, different OS and types of machines have different ways to manipulate the multi-core, thus developers would need to write several versions of the same app to run on different platforms, which will be a huge burden.<br><strong>Q: I believe if that’s the case, there must be some genius trying to solve it. One saying in computer science is “there must be some connection by interlayers between a gap.”</strong><br>A: Exactly. In the computer world, it always will happen. In fact, in the past decades, many individals, institutions, universities and companies have developed many tools to make multi-core programming much easier, like OpenMP, which makes parallelism on shared memory machines much easier.<br><strong>Q: Sounds great! Is OpenMP a library? Sometimes, it is not an easy job to compile and link an library to user’s programs. Especially for the libraries with poor installation guides.</strong><br>A: No. It isn’t. It is just a set of APIs built in your compiler, like GNU GCC, LLVM, Intel C Compiler, IBM XL etc. The OpenMP is evolving, and the compilers keep updating their supports to OpenMP (see <a href="https://www.openmp.org/resources/openmp-compilers-tools/" target="_blank" rel="noopener">OpenMP Compilers</a>). You don’t need any extra installations besides your compiler.</p>
<p><strong>Q: I like this design, a very clean way. Now everything is ready (just compiler, no extra preparation!), could we start?</strong><br>A: Sure, but could you tell me what compiler you use?<br><strong>Q: Just GNU GCC compiler.</strong><br>A: In fact, GCC is a great opensource and free compiler, but to learn the parallelism technique, I want to start from a commercial compiler: Intel C/C++ compiler: icc/icpc. It has been optimized for parallelism for a long time. Also it has more interesting functions.<br><strong>Q: I can’t afford its price probably.</strong><br>A: Every student has a one-year free license. It has been included into the Intel Parallel Studio XE, see<a href="https://software.intel.com/en-us/c-compilers" target="_blank" rel="noopener">Intel Parallel Studio XE</a>.<br><strong>Q: That’s great!</strong><br>A: Parallelism has a hierarchy with many differnt layers. We can start from the simplest case. What’s the simplest operation you can think about in your code?<br><strong>Q: Addition operation to two scalars or vectors. Because I am doing research on computational science, the most operations are arithmetic. I want to parallelize the addition operations on vectors. For example, $c[i]=a[i]+b[i]$, and each array $a[\ ],\ b[\ ],\ c[\ ]$ has 100 elements. I want to add those 100 elements at the same time. Is it possible?</strong><br>A: Yes. There are many ways to realize that. I call them different parallelism levels:<br><img src="/images/parallel_layers.png" alt="parallel_layers"></p>
<ol>
<li>The highest level is you can split the 100 elements and send one element per array $a[i]$ and $b[i]$ to 100 CPU cores and do the addition operations. At the end, one core gather all $c[i]$ from other 99 cores. As you see, there is very much communication between cores. In fact, it’s hard to have one single machine with 100 cores, so usually you have like 5 machines, we call them nodes, with 20 cores for each. An problem comes here. Because machines are normally connected via Ethernet network, whose bandwidth is about 10 Gigabit per second, the cost on communication is the dominated factor of speedup. Of course, some latests clusters use Infiniband hardware with higher bandwidth <a href="https://en.wikipedia.org/wiki/InfiniBand" target="_blank" rel="noopener">Infiniband Wik</a>. Even for those cores in the same machine, their memories are not shared. Each core has its own part of physical memory on that node. Unlike the cross-machine communication, within one machine, cores can communicate with each other with a much faster speed (see DDR4’s bandwidth is ~60 Gbit/s <a href="https://www.techspot.com/news/62129-ddr3-vs-ddr4-raw-bandwidth-numbers.html" target="_blank" rel="noopener">DDR4 bandwidth</a> and also the MPI library and OS will do some optimization on this), so the cross-node message passing is the bottle-neck.</li>
<li>The second highest level is that you can put those 100 elements to the 20 cores within one machine. Each core will take 5 elements from array $a$ and $b$ and do 5 addition operations. This time, some cores can share the memory, thus there is no need to send and receive any data between cores. This is the so called multi-threading technique.</li>
<li>The next level is the parallelism on a single core. There are some concepts, which I even don’t know much right now, like pipelining, superscalar execution, out-of-order execution and so on. Currently, I will only focus on a situation called vectorization. It is easy to guess what it will do. For the previous example, if we only use a single core to add array $a$ and array $b$, we don’t need to add their elements one by one, like adding scalars intead of vectors. Many modern CPU supports vectorization in hardware, because it has the so-called vector register, which can be used for summing up a segment of array $a$ and $b$ within one clock cycle. A simple picture is below</li>
<li>Other types of parallelism, for example add some other devices (e.g. GPU) to help CPU on the computation intensive tasks. This topic has been covered in one of my previous blogs in <a href="https://feilinx.com/2019/05/05/burn-gpu-calorie-3/">GPU blog</a>.</li>
</ol>
<p><strong>Q: Hmm… so many levels of parallelism. parallel programming sounds very complex. If only we can increase the CPU frequency more! Now there will be no free lunch any more. Programmers have to learn how to make their applications run in parallel to scale.</strong><br>A: Exactly, you are right. The CPU frequency almost approaches the physical limit. We have to admit this fact. Before a new technology comes up and replace the current technology, computer scientists need to think about how to scale. Parallelism seems to be the most promising one. Actually, most of current programs, e.g. various apps in your mobile phone, do not exploit the benefits of the multi-core hardware, so software should catch up!<br><strong>Q: Really? That’s a huge waste. I want to learn parallel programming. Could we start from the vectorization?</strong><br>A: Sure. It is in a relatively low level of parallelism. It’s hard to imagine how multiple arithmetic operations can be done using one clock cycle. It must be implemented in the hardware, right?<br><strong>Q: Agree. Software can not solve this kind of problems.</strong><br>A: Yes. At the beginning, all the CPUs are scalar processors, which can only deal with scalars. Then some scientists think about how to speedup. Because in many numerical code, operations on a large vectors are very common, so that each element of a array executes the same instruction. They want to let the CPU execute those same instructions at the same time, so vector processors come out. It can’t be realized from software side, it is a new type of CPU. This kind of CPU can conduct arithmetic operation on a set of several scalars, which is called a “vector”. Before talking about the vector addition, do you know what happens when two scalars are added in CPU?<br><strong>Q: Yes. The CPU firstly retrieve these two scalars into registers, and then add them up using the ALU, and finally write the result back to the memory. Is that right?</strong><br>A: Right. Similarly, now we want to add 2 arrays, each has 4 elements. The “powerful” CPU firstly retrieve these two vectors into “vector registers”, and then add $a[i]$ and $b[i]$ for $i=0,1,2,3$ using a single “vector” instruction, like below<br><img src="/images/vectorization.png" alt="parallel_layers"><br><strong>Q: Amazing. Which kind of CPUs can support vectorization?</strong><br>A: I only know a little about Intel CPUs, so I can only tell you the Intel stuff for now, but it should be similar to AMD cores. The vectorization capability of Intel CPU is supported by the instruction set. It has been evovling for almost two decades from 64-bit MMX (meaningless initialism<a href="https://en.wikipedia.org/wiki/MMX_%28instruction_set%29" target="_blank" rel="noopener">MMX-Wikipedia</a>) to 128-bit SSE (Streaming SIMD Extentions), SSE2, SSE3, SSE4.2, and then to 256-bit AVX (Advanced Vector Extentions), AVX2 and now the 512-bit AVX-512. The number in xx-bit means how many bits can be stored in a vector register where the data can be processed together. Of course, the larger the vector register is, the better the performance will be.<br><strong>Q: Hmm… these names are very unfamiliar for me. Normally when I buy a computer, it writes like Intel i3, i5 or i7. How can I know their instruction sets?</strong><br>A: The i3/i5/i7 belongs to the Intel Core series. This series is mainly for general purpose, like gaming, graphics, or office. You can check their instruction sets in Intel website (e.g. <a href="https://www.intel.com/content/www/us/en/products/processors/core/i7-processors/i7-8565u.html" target="_blank" rel="noopener">Intel Core i7-8565U</a>). The i7 can only support up to AVX. Usually for scientific computing, we should use Intel Xeon series because it has more cores inside and better vectorization. For example, the Intel Xeon Phi 7250 has 68 cores and supports AVX-512. (<a href="https://ark.intel.com/products/94035/Intel-Xeon-Phi-Processor-7250-16GB-1_40-GHz-68-core" target="_blank" rel="noopener">Intel Xeon Phi 7250</a>).<br><strong>Q: I see. Even the Intel CPU has many kinds for different purposes. OK, let’s go back to the vectorization. Assume I have a Intel Xeon machine, which supports vectorization, do I need to do something to let the machine or my program to exploit this feature? Just like my smartphone, it has many physical sensors to sense the rotation and movement of my phone, but it will only function after I install a racing game app. I remember my teacher never talked about vectorization when I took the C/C++ course in the first year of my undergraduate.</strong><br>A: Good question. The vectorization is more related to the hardware, so it will be too much if it is included into a C/C++ course. The instruction set is what the CPU can do, which we can not change, and the code, which is in high level, is what our programmers can do. It seems that if a programmer doesn’t pay any attention on vectorization when he/she is programmin, the AVX-512 instruction set will be wasted. Is it right?<br><strong>Q: It is right for me. We programmers have to tell the machine “go to execute these additions using vectorized instruction” explicitly via some code, right?</strong><br>A: Correct but not common. For Intel CPUs, there is a good way to exactly control the vectorization, called Intel Intrinsics. The intrinsics is pretty much like a language between C and Assembly. It will be directly translated into corresponding assembly-level vectorized instruction by the Intel Compiler, but it is hardware dependent, thus less flexible. Here is an example. The following function is a intrinsics to multiply a and b, then add the intermediate results with c.<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">__m128d _mm_fmadd_pd (__m128d a, __m128d b, __m128d c)</span><br></pre></td></tr></table></figure><br>“fmadd” means “fused multiplication and addition”. “pd” means “packed double precision floating numbers”, where “packed” is equivalent to “vector”, which is opposite of scalar. “__m128d” is a data type of length = 128-bit. This kind of 128-bit number will be stored in xmm vector register (128-bit). There are 3 different kinds of vector registers shown in following table</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>vector register</th>
<th style="text-align:center">length (bit)</th>
<th style="text-align:center">supported ext.</th>
</tr>
</thead>
<tbody>
<tr>
<td>xmm</td>
<td style="text-align:center">128</td>
<td style="text-align:center">SSE, AVX, AVX512</td>
</tr>
<tr>
<td>ymm</td>
<td style="text-align:center">256</td>
<td style="text-align:center">AVX, AVX512</td>
</tr>
<tr>
<td>zmm</td>
<td style="text-align:center">512</td>
<td style="text-align:center">AVX512</td>
</tr>
</tbody>
</table>
</div>
<p>Therefore, to use ymm vector registers (if supported), programmers have to call another intrinsics,<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">__m256d _mm256_fmadd_pd (__m256d a, __m256d b, __m256d c)</span><br></pre></td></tr></table></figure></p>
<p>which makes too much trouble when tranplanting a code from one machine to another, because the intrinsics is hardware-dependent. Normally, we won’t do that.<br><strong>Q: That puts too much burden to programmers to develop as well as maintain. Is there any better way? like a wrapper of intrinsics?</strong><br>A: Correct! There is one “wrapper”! But as far as I know, there is only one explicit directive, which is hardware independent, to guide the vectorization. It is a directive provided by OpenMP:<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp simd</span></span><br></pre></td></tr></table></figure></p>
<p>“simd” means single intruction multiple data, which is similar to the idea of vectorization. If a loop is acted by the above directive, the compiler will vectorize the body of loops forcely.<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp simd</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;n; i++) &#123;</span><br><span class="line">    c[i] = a[i] + b[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>The array a[] and b[] will be put to available vector registers (xmm, ymm, or zmm) in the current hardware. No need to worry about data type or vector length for programmers. The only thing is to make sure there is no data dependence between the components of vectors. A bad example of vectorization is<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp simd</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (i=<span class="number">2</span>; i&lt;n; i++) &#123;</span><br><span class="line">    a[i] = a[i<span class="number">-1</span>] + a[i<span class="number">-2</span>];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>The above vectorization will produce wrong results because the array a[]’s elements are dependent to each other.<br><strong>Q: This directive is very useful. I think it’s enough for vectorization, right?</strong><br>A: Not really. There are many other things you must be careful about, which will be talked about next time!</p>
<p>Note:<br>Most content in this post comes from the online free course “Fundamentals of Parallelism on Intel Architecture” available at <a href="https://www.coursera.org/learn/parallelism-ia" target="_blank" rel="noopener">https://www.coursera.org/learn/parallelism-ia</a>.</p>
]]></content>
  </entry>
  <entry>
    <title>Burn GPU&#39;s Calories (3)</title>
    <url>/2019/05/05/burn-gpu-calorie-3/</url>
    <content><![CDATA[<p><strong>Q: From on the previous 2 blogs, I’ve grasped the main idea of parallelism in CPU. I think it is already very powerful, so why do people use GPU to do intensive computing? Why not add more and more cores in CPU?</strong><br>A: Because of the complex structure and design pattern of CPU cores, it is impossible to put thousands of cores in a CPU chip. However, GPU has a totally different design and the ‘core’ in GPU is extremely simplified (only the arithmetic related units are remained), so that to achieve massive parallelism for large scale intensive computation, GPU is the best choice for now.<br><strong>Q: I see, so the core in CPU is very powerful, but that in GPU is very weak. Is there any quantitative way to measure that?</strong><br>A: Of course. The speed clock in CPU’s core is about 2~5GHz, but it’s is about 500-1300MHz in GPU’s core. In a CPU’s core, it has multiple ALU, FPUs, so may support multi-threading execution. However, in a GPU’s core (actually called CUDA core, named by NVIDIA), it has only one ALU and/or one FPU, so no multi-threading capability. Look at the picture below<br><img src="/images/cpu_gpu_core.png" alt="CPU"><br><a id="more"></a><br>The CPU’s core is like a math professor in a college, but the GPU’s core is similar to a student in a primary school. To do an intensive computing task in most science and engineering, a famous mathematician is not necessarily faster than 2000 students, because all the tasks are just simple arithmetic operations.<br><strong>Q: I see. The massive parallelism really changes things. You mean the GPU is designed to meet this emerging requirement in science and engineering?</strong><br>A: Not really. The history is a little complex. In fact, initially, the GPU card was just for visualization purpose in gaming. Because there are many pixels (10K~100M) in a screen and their colors (RGB values) need to be updated 20-60 times every each second, if this task is sent to CPU, the pixels have to be updated one by one (or several by several depending on number of cores in CPU), which is not affordable, especially with the increasing screen resolution and refreshing rate. For example, the refresh rate of a gaming monitor, ASUS ROG Swift PG279Q, can be overclocked to 165Hz!<br><strong>Q: That’s impossible for CPU to handle.</strong><br>A: Yes. The initial GPU is only for gaming purpose, but later on, maybe some scientists found why not use this high parallel structure to do computation, e.g. particle simulation? Then the general purpose GPU (GPGPU) was created, and then more and more scientists and engineers, such as people in academics, oil companies, NASA and many national labs, purchased GPUs to accelerate their simulations. A big market was emerging suddenly. Many small GPU manufacturers were created to cater this market.<br><strong>Q: Who is the biggest winner up to now?</strong><br>A: NVIDIA. Nowadays, there are only three key players in ths market: Intel, AMD and NVIDIA. Two of them are actual CPU manufacturers as well and they keep incorporating GPUs into their CPUs, while NVIDIA keeps making discrete GPUs as an extension to CPUs. Nowadays, when you see a NVIDIA logo attached on a desktop PC or laptop, it means the NVIDIA GPU card is installed. Here is the history of market value of Intel and NVIDIA.<br><img src="/images/intel_nvidia_value.png" alt="CPU"><br>The NVIDIA is almost like boosted by a rocket during the recent 5 years.<br><strong>Q: Impressive rising. The Intel has a history of 50 years, but the NVIDIA is only 26 year old. Now they have comparable values. I think NVIDIA will eat most of the GPU market soon.</strong><br>A: Not really. NVIDIA is only popular in desktop environment, while in mobile market, a completely different set of palyers emerge: QualComm and Broadcom. Therefore, in the future there are still many possibilities.<br><strong>Q: I see…what kind of GPUs would you like to talk about? Integrated or discrete?</strong><br>A: NVIDIA’s discrete GPUs, because they are widely used in many supercomputers like TOP1 Summit by OakRidge National Lab. The GPUs provide its 95% computing power.<br><strong>Q: Hard to imagine. It seems like my previous knowledge of CPU is going to be useless soon.</strong><br>A: No. The CPU is very important, because the current GPUs are not processors but “co-processors”. They work under the supervision of a host CPU. All of the initial data in GPU must come from CPU via the connection, e.g. PCI Express bus. This mode is almost like a commander + workhorses in figure below<br><img src="/images/cpu_gpu_commander.png" alt="CPU"><br>Like the radio cards and wifi units, the GPUs are just extensions in PCI bus, after its driver is installed, the mechanism of GPU is very similar to the Pthreads in my last blog. Programmers just need to create functions for each GPU core (like thread in CPU) and let it run!<br><strong>Q: Hmm…perfect! If they are similar, now I can do the GPU programming using my existing development environment, e.g. LINUX+GCC？</strong><br>A: No…not that easy case. Because CPU cores and GPU cores are completely different hardwares, so they have different “instruction set architectures” (ISA), which means they use different languages. Image, a commander uses English to give orders to the workhorses who can only understand spanish. That won’t work. GCC can only translate your code to the language used by CPU, so GPU can not understand it and will do nothing.<br><strong>Q: Reasonable. Things are more complex than I thought. It seems we need to develop a new language understood by GPU.</strong><br>A: Yes. In GPU, the assembly level instructions are quite different from CPU, but it is not a realistic thing to let our scientists and engineers learn a brand new programming language just to accelerate computation. In fact, in some early stage of GPUs, some geeks used some low-level languages to program for GPUs, but of course, it was too hard. Therefore, some ideas come out, like CUDA and OpenCL. Here I will only talk about CUDA (nvcc compiler) released by NVIDIA in 2007. To alleviate the pain to learn a new language, it just defines many new keywords based on C language, therefore the learning is much easier. Also for compiling, “nvcc” compiler can automatically seperate the host code and the device code and compile them into different assembly level codes for different hardwares.<br><strong>Q: This is very helpful for all learners. Before programming, could you show some structures of GPU? I still wonder how it can have thousands of cores in it.</strong><br>A: Sure. Look at the figure below<br><img src="/images/gpu_struct.png" alt="CPU"><br>It looks very similar to CPU, but different from CPU, GPU has no L3 cache. The last level cache (LLC) is L2. All the computing units are integrated into so called streaming multiprocessor (SM). It is pretty much like the physical core in CPU from outside, but the inner structures are quite different. See the picture below<br><img src="/images/gpu_sm.png" alt="CPU"><br>Compared with physical cores in CPU, there are not so many built-in controllers, but many cores inside. As I said before, each core has 1 ALU and/or 1 FPU. Another difference is the register files are shared by all cores. This is the reason why some people don’t want to call the processing units in GPU “cores”, because the cores don’t have their own registers. Also there are many Load/Store units (LD/ST) to handle memory access between cores and caches. SFU is for special function calculation, like sin(), cos(), square root, logarithm, and exponential functions.<br><strong>Q: I know instruction cache is to store machine code for execution. What’s warp and warp scheduler?</strong><br>A: Good question. Warps make programming tricky but computing much faster. Because of some inner design in hardware, every 32 cores constitute a “super-thread”. If the logics of these 32 cores are the same, they can execute simultaneously, which means there is no divergence. However, if the divergence happen, the diverged parts have to be executed serially by different cores in that warp. Like the figure below<br><img src="/images/warp.png" alt="CPU"><br>This feature puts more pressure to programmers to try to avoid warp divergence for performance purpose. Actually, programming on GPU usually needs more rounds of coding optimization before the production run, because there are many features like warp in GPU, which can influence the performance significantly.<br><strong>Q: It seems like the CPU takes over much burden from programmers to itself.</strong><br>A: Yes. CPU has many advanced features, which can do much optimiztion for programmers. Even a new programer writes a moderately good code, but it is still possible that CPU can make it run perfectly through super-scalar, piplining techniques automatically. However, for GPU, it puts all pressure to programmers to handle every details. It is the price that programmers must pay for the superior parallelism. Today’s knowlege is already a little bit much. Next time, we will dive into GPU programming.<br><strong>Q: See you next time.</strong></p>
]]></content>
  </entry>
  <entry>
    <title>《数学与人类文明》Note</title>
    <url>/2019/03/04/math-human-civilization/</url>
    <content><![CDATA[<p>多年以前，在一个机缘巧合之下，认识了浙江大学的蔡天新老师，之后便“别后音书两不闻”。前几天，Kindle的自动推送里居然出现了他的一本书，叫《数学与人类文明》。刚看到这个书名时，觉得这个标题既空泛又过于宏大，所以我推测这应该是一套枯燥冗长的“学院派”系列丛书。而且书名里直接写到“人类文明”，不免让人感受到作者在隐隐中透露出的那种”唯我独尊”式的自夸和自傲。以我的经验，这类大部头只可能出现在两种地方。一是大学的图书馆，而且这类书往往会被放在最人迹罕至的书架底层的角落里，唯一的价值是用来刷这本书的存在感；二是公司董事长办公室的书架上，而且常常会被放在最显眼的位置，唯一的价值是用来刷公司的存在感。但是当我点开后发现，相比较于它的书名，这其实是一本小书，一共也就20多万字，那就拿来看看也无妨。这本书从数学的起源讲起，讲到阿拉伯数字，进制，到演绎推理，再到打破正统追求自由的现代数学，颇有一种读《XX简史》的意味。其中最让我感兴趣的就是它比较详细地介绍了从先秦到宋元时期，在中国大地上诞生的数学和数学家们。读到那一段时期的历史时，在倍感亲切之余也感到非常惋惜，因为中国古代很多曾经先进的思潮由于各种原因被戛然而止。最后，这本书的一大特色就是把数学和艺术从时间发展顺序上联系了起来，虽然不免招致“强拉硬拽”的批判，但也或许揭示了某些深层次的问题，总之给我带来了思想冲击。<br><a id="more"></a></p>
<h2 id="1-数学的起源到希腊文明"><a href="#1-数学的起源到希腊文明" class="headerlink" title="1 数学的起源到希腊文明"></a>1 数学的起源到希腊文明</h2><p>数学起源于最古来的“计数”，在之前的《计算进化史》中也有类似的描述。比如人们把打来的猎物进行储存，就需要用绳子打结来记录。当数字越来越大时，就催生了进制。因为一年中有12个朔望月，所以产生了12进制，比如1英尺等于12英寸，1先令等于12便士，1英镑等于12盎司。巴比伦产生了60进制，比如每小时60分钟，每分钟60秒，这个一直沿用至今。不过在世界范围内最普遍的还是10进制，比如古埃及的象形数字，中国的甲骨文数字，希腊的阿提卡数字，印度的婆罗门数字，都纷纷采用了10进制。这其中的原因，恐怕很难找到一个令所有人信服的解释，但是亚里士多德的一个解释是“10进制的广泛采纳，只不过是由于我们生下来有10个手指这样的一个解剖学事实。”亚里士多德首先使用了形式逻辑学的“三段论”，这被以后的推理演绎视为圭臬。</p>
<p>数学真正意义上的发展要从希腊开始讲起，那里的人们出身于游牧民族，没有君临一切的思想枷锁，更喜欢接触新鲜事物。有关这一点，在中国那一章里也有类似的体现。毕达哥拉斯就是这个时期的代表人物，如果对他不熟没关系，那么下面这3位，你肯定听过：哥白尼，伽利略，莱布尼兹。前面这3位都自称是毕达哥拉斯思想的最后一位传人，可想而知毕达哥拉斯应该属于乔布斯式的人物。此外，亚历山大学派的欧几里得的《几何原本》第一次汇总了正统的几何学，挤掉了前人的著作而成为官方指定的“红宝书”。阿基米德除了因为洗澡发现了浮力定律之外，还得到了当时最精确的圆周率3.14。这里先记住这个记录，因为这个记录将会被魏晋南北朝时期的刘辉碾压，后者又会被祖冲之碾压，而现在的计算机又可以把所有人碾压，所以说数学可以被看做是一部碾压与被碾压的历史。</p>
<h2 id="2-中国（先秦到宋元）"><a href="#2-中国（先秦到宋元）" class="headerlink" title="2 中国（先秦到宋元）"></a>2 中国（先秦到宋元）</h2><p>在先秦的诸子百家时期，其实名家和墨家就提出了抽象逻辑，但是当时这两家的影响力远小于儒家，道家和法家，而后面这三个又很少关心数学问题，所以抽象逻辑的思想并没有广泛流传。到了西汉时期，《周髀算经》里提到了勾股定理，这个时间比毕达哥拉斯要早，但是可惜没有证明过程。直到公元3世纪的三国时代，才由东吴的数学家赵爽完成了证明过程。《九章算术》里出现了无理数的概念，但是没有深究。到了魏晋南北朝时期，因为长期的国家分裂和杀戮战争，人们不再独尊儒术，而去追求崇尚自然和超然物外的风流自赏（即魏晋风度）。对待自然，思辨之风又复兴了起来，于是中国古代的数学迎来了一个小高潮。刘辉开创了逻辑证明的先河，写了《海岛算经》，用割圆术把圆周率算到了3.1416。祖冲之在计算历法时，基于刘辉的方法，把圆周率算到了7位小数；再用刘辉的“牟合方盖”得到了球体的计算公式，写了一本风靡国子监和太学院的畅销书《缀术》，可惜很快失传。但是，后来随着隋唐大一统的盛世到来，这种追求自然的风潮戛然而止。到了两宋时期，沈括，杨辉，秦九韶，贾宪分别提出了很多代数学的方法，很多都领先西方600年以上，可惜……没有如果。</p>
<h2 id="3-欧洲文艺复兴到法国大革命"><a href="#3-欧洲文艺复兴到法国大革命" class="headerlink" title="3 欧洲文艺复兴到法国大革命"></a>3 欧洲文艺复兴到法国大革命</h2><p>到了15世纪，欧洲文艺复兴。几何学被应用到绘画中，产生了透视法。17世纪，牛顿在自己的笔记本上记录了自己发明的正流数术（微分）和负流数术（积分），然后给笔记本取名“废书”，大有马云“最后悔的事情就是创立阿里巴巴”的感觉。约翰伯努利发明了一种求微分的方法，但是当时没有发表，后来被学生洛必达收录在了自己的小书中，虽然注明了是自己的老师发明的方法，但是这个方法依旧被叫做“洛必达法则”。看到这里，我的内心独白就是“请问这是什么神仙操作？”后来法国逐渐成为欧洲的数学和文学中心。哈密顿13岁的时候就已经掌握了13门语言，正当他想把汉语作为第14门语言时，父母双亡，于是在一个朋友带领下学数学去了。最值得一说的是黎曼，他打破了过去欧式几何的绝对正统而创立了非欧几何，为后来的理论物理和新时空观的建立打下了基础。与此同时，受相同的思潮影响，爱伦坡和博德莱尔打破了浪漫派诗人的绝对统治，创立了现代主义文学。</p>
<h2 id="4-二十世纪后"><a href="#4-二十世纪后" class="headerlink" title="4 二十世纪后"></a>4 二十世纪后</h2><p>20世纪后，数学走向抽象化和公理化。与此同时，艺术也开始变得抽象。塞尚，梵高等等一系列名字，大家一定不陌生，这二者之间如果完全没有联系是说不过去的。截至目前，数学依旧在激烈地分化着，未来究竟会把人们带向何方，尚未可知。不过可以确定的是某种思潮的建立肯定会分化出新的艺术流派。</p>
<p>读完这本“简史”，除了一小部分的惊叹和惋惜之外，其实更多的是理解与期待。经常有人把中西的数学发展对立起来，甚至完全否认中国古代曾经有过“数学”，或者认为其不值得的一提。通过这本小书，其实会发现上面的观点完全错误，因为中国古代有很多数学发现早于西方几百年。但是不得不说，中国的数学更多地叫“算学”，是以实际的“计算”来作为源动力而很少主动去探究其内涵的。比如祖冲之计算圆周率的目的就是为了更准确地计算闰年的历法。这些与其说是中西差异，不如说是不同历史人文背景下的人在不同历史时期的表现不同。</p>
]]></content>
  </entry>
  <entry>
    <title>Burn CPU&#39;s Calories (2)</title>
    <url>/2019/02/23/burn-cpu-calories-2/</url>
    <content><![CDATA[<p><strong>Q: Last time, we talked about multi-threading techniques in parallel programming. I saw the 4-thread version of the code doesn’t show good speedup in your 4 core/8 thread (4C/8T) laptop, why?</strong><br>A: Generally speaking, there are only two factors of a computer’s performance. One is the power of CPU (frequency, number of cores, number of ALU and FPU, registers, etc.), and the other is the memory, so a short answer to your question is MEMORY.<br><strong>Q: Memory? I think the memory is sufficient. The entire matrix is just 20MB, but your laptop has 12GB memory available, I believe.</strong><br>A: The size of memory is enough, but the bandwidth of memory is already saturated.<br><strong>Q: Bandwidth? What does it mean?</strong><br><a id="more"></a><br>A: It means the amount of data can be transferred from the main memory to CPU per second through the <strong>memory bus</strong>. Because the data (matrix in our example) is stored in the main memory, but the operations must be executed in CPU, so the data must be read in to the CPU’s cache and then written back to the main memory.<br><strong>Q: I still can not image the picture of data transfer.</strong><br>A: Look at the following picture. Ignore the “uncore, queue, X99 chipset, GPU etc.” for now. All the data directly accessed from CPU is from L3 cache. The data in the main memory is fetched by the memory controller to the L3 cache through the memory bus. The <strong>most important</strong> thing to be noted is all of the threads share the same memory bus, which means the bandwidth is a upper limit of the entire memory access rates of all threads.<br><img src="/images/cpu.jpg" alt="CPU"><br><strong>Q: I see, so I think there should be many kinds of bandwidth, because the data has to be transferred for many times before getting involved to the physical cores, like from memory to L3, from L3 to L2, from L2 to L1. </strong><br>A: No. The bandwidth is specifically referred to the transfer speed from memory to L3, because it is the bottleneck. Look at the following table</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type of storage</th>
<th style="text-align:center">access latency (cycles)</th>
</tr>
</thead>
<tbody>
<tr>
<td>L1 cache</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td>L2 cache</td>
<td style="text-align:center">11-12</td>
</tr>
<tr>
<td>L3 cache</td>
<td style="text-align:center">22</td>
</tr>
<tr>
<td>Memory</td>
<td style="text-align:center">200-400</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Q: What a huge latency between L3 cache and memory!</strong><br>A: Agree, so the bandwidth is critical for all memory-intensive programs.<br><strong>Q: Wait, what do you mean by “memory-intensive program”?</strong><br>A: As I said, there are two big factors of performance. If the bottleneck of a program is the capability of computation, like number of ALU, FPU, it is called a core-intensive program. If the computation capabilities are enough, but it starves for more data from the memory, which means it suffers from the bandwidth, it is called a memory-intensive program.<br><strong>Q：I see… Now I think I can guess the solution of my question “why our program can not show much speedup with more than 3 threads”. More threads mean more data requests at the same time, so it puts more pressure to the memory controller and memory bus. For the 1-, 2-, 3-thread versions of our program, the amount of requested memory rate is not that big, so they are still core-intensive, which means more threads can provide more speedup. However, with 4 or more threads, the amount of requested memory rate hits the uppper limiter of the data transfer speed (bandwidth), so it becomes a memory-intensive program. It also explains why the time costs of 5-10 thread versions are quite similar, because all of them are limited by the same bandwidth! It means this code is never limited by computation units (e.g. ALU, FPU). Of course, there are no arithmetic operations at all.</strong><br>A: Correct! If the maximum score is 10, I would like to give you 20, because your answer already goes beyond your question.<br><strong>Q: Although I am correct, I feel sad because it means we can do nothing, except buying a new computer, to improve it anymore, because it already hits the hardware limit.</strong><br>A: Not really. In fact, the bandwidth is just in ideal situation. In most real-world cases, we can not reach that ideal bandwidth. For example, our matrix has 1800<em>2400 integer entries, so it occupies 16MB. To flip it, we need to read and write each entry once, so in total we have 16MB reading access and 16MB writing access. I did a bandwidth testing on my computer by an opensource tool (<a href="https://zsmith.co/bandwidth.php" target="_blank" rel="noopener">https://zsmith.co/bandwidth.php</a>), it shows<br>
<p style="background-color: #000000; color: #00FF00">
Sequential read (64-bit), size = 128 B, loops = 2031091712, 49582.0 MB/s <br>
Sequential write (64-bit), size = 128 B, loops = 1002438656, 24462.2 MB/s <br>
</p>
<br>Therefore, the ideal time cost of a program would be 9.87e-4 seconds. This value is valid for multi-threads programs, because it is the upper limit of memory access capability. It should be noted that the above value is just an rough estimation for reference. From our real time costs, we can see there is much space for optimization especially for vertiacal flipping. We need to do something to optimzie the memory access pattern to dig the memory access. The current pattern is not efficient.<br><strong>Q: Oh? Access pattern?</strong><br>A: Yes. It relates to the structure of the memory. The DRAM is accessed one row at a time. Each row is the smallest amount of memory to be fetched (about 2-8KB in modern DRAMs), which means even the CPU only requests 1 integer (4 Byte), the memory controller will still fetch 2-8KB data from the main memory to L3 cache. The entire latency is 200-400 cycles as stated in the table before.<br><strong>Q: Hmm… In our code, I think it requests the matrix’s entries one by one. It is tatally a waste of time.</strong><br>A: Yes. <strong>Accessing memory should be in large chunks</strong>. We hope the CPU can fetch all the needed data to the caches at first and do some flipping operations within the caches, then write them back to the main memory.<br><strong>Q: Yes, please tell the CPU “hey, put this chunk of data into the cache, and then just use data in the cache”.</strong><br>A: Unfortunately, that’s hard, almost impossible. The reason is caches are totally hideen from programmers and they are handled automatically by the OS…<br><strong>Q: … I am waiting for your “but”.</strong><br>A: But, programmers can always give some hints to the OS to use the caches more efficiently. For example, if a chunk of data is frequently used within a loop, that amount of data will be cached. Here are the memory optimized versions of our codes<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">MTFlipHMem</span><span class="params">(<span class="keyword">void</span> *tid)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> *<span class="built_in">buffer</span>;</span><br><span class="line">    <span class="keyword">int</span> ts = *((<span class="keyword">int</span>*)tid);</span><br><span class="line">    ts *= row/num_threads;</span><br><span class="line">    <span class="keyword">int</span> te = ts+row/num_threads<span class="number">-1</span>;</span><br><span class="line">    <span class="built_in">buffer</span> = (<span class="keyword">int</span>*)<span class="built_in">malloc</span>(col*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=ts;i&lt;=te;i++)&#123;</span><br><span class="line">        <span class="built_in">memcpy</span>((<span class="keyword">void</span>*)<span class="built_in">buffer</span>, (<span class="keyword">void</span>*)matrix[i], col*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;col/<span class="number">2</span>;j++)&#123;</span><br><span class="line">            <span class="keyword">int</span> temp = <span class="built_in">buffer</span>[j];</span><br><span class="line">            <span class="built_in">buffer</span>[j] = <span class="built_in">buffer</span>[col-j<span class="number">-1</span>];</span><br><span class="line">            <span class="built_in">buffer</span>[col-j<span class="number">-1</span>] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">memcpy</span>((<span class="keyword">void</span>*)matrix[i], (<span class="keyword">void</span>*)<span class="built_in">buffer</span>, col*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">free</span>(<span class="built_in">buffer</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">MTFlipVMem</span><span class="params">(<span class="keyword">void</span>* tid)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> *<span class="built_in">buffer</span>, *buffer2;</span><br><span class="line">    <span class="keyword">int</span> ts = *((<span class="keyword">int</span>*) tid);</span><br><span class="line">    ts *= row/num_threads;</span><br><span class="line">    <span class="keyword">int</span> te = ts+row/num_threads<span class="number">-1</span>;</span><br><span class="line">    <span class="built_in">buffer</span> = (<span class="keyword">int</span>*)<span class="built_in">malloc</span>(col*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    buffer2= (<span class="keyword">int</span>*)<span class="built_in">malloc</span>(col*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=ts; j&lt;=te; j++)&#123;</span><br><span class="line">        <span class="built_in">memcpy</span>((<span class="keyword">void</span>*)<span class="built_in">buffer</span>,  (<span class="keyword">void</span>*)matrix[j], col*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">        <span class="built_in">memcpy</span>((<span class="keyword">void</span>*)buffer2, (<span class="keyword">void</span>*)matrix[row-j<span class="number">-1</span>], col*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">memcpy</span>((<span class="keyword">void</span>*)matrix[row-j<span class="number">-1</span>],  (<span class="keyword">void</span>*)<span class="built_in">buffer</span>,  col*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">        <span class="built_in">memcpy</span>((<span class="keyword">void</span>*)matrix[j],        (<span class="keyword">void</span>*)buffer2, col*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">free</span>(<span class="built_in">buffer</span>);</span><br><span class="line">    <span class="built_in">free</span>(buffer2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>In the innermost loop of <strong>MTFlipHMem()</strong>, only the buffer is used and its value is got from <strong>memcpy()</strong>. In the <strong>MTFlipVMem()</strong>, the <strong>memcpy()</strong> replaces the previous one-by-one memory access pattern.<br><em>*Q: What’s the speedup of this optimization?</em></em><br>A: Look at the timing information below<br>
</p><p style="background-color: #000000; color: #00FF00">
Time cost to vertically (MT version, TH = 1) is 3.939e-02 seconds.<br>
Time cost to horizontally (MT version, TH = 1) is 4.494e-03 seconds.<br>
Time cost to vertically (MT version, TH = 2) is 2.014e-02 seconds.<br>
Time cost to horizontally (MT version, TH = 2) is 2.834e-03 seconds.<br>
Time cost to vertically (Memory Opt) (MT version, TH = 1) is 4.851e-03 seconds.<br>
Time cost to horizontally (Memory Opt) (MT version, TH = 1) is 2.868e-03 seconds.<br>
Time cost to vertically (Memory Opt) (MT version, TH = 2) is 3.607e-03 seconds.<br>
Time cost to horizontally (Memory Opt) (MT version, TH = 2) is 2.020e-03 seconds.<br>
</p>
<br>Remember our previous estimation? 9.87e-4 seconds. We are very close to it! (50% of ideal bandwidth is already very high)<br>The speedup due to the optimization of memory access pattern is summarized in the following table<p></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Tables</th>
<th style="text-align:center">speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td>vertical flip</td>
<td style="text-align:center">12X</td>
</tr>
<tr>
<td>horizontal flip</td>
<td style="text-align:center">1.4X</td>
</tr>
</tbody>
</table>
</div>
<p>The reason why the vertical flipping has much more speedup than the horizontal flipping is the horizontal flipping is already close to the ideal bandwidth limit.<br><strong>Q: Nice. Now I know the limit of the hardware and how to program the software to reach that limit. At this stage, I can say “we can not improve this program anymore on this computer” with confidence.</strong><br>A: No…You can.<br><strong>Q: Why?</strong><br>A: Look at the NVIDIA logo on my laptop, which means it has GPU card installed. When the CPU is burnning the calories at the full speed, the GPU is just sleeping there. Why not wake it up?<br><strong>Q: I am eager to dive into the GPU world.</strong><br>A: See you next time. All of today’s code is available here: <a href="https://onlinegdb.com/SJhVBUJU4" target="_blank" rel="noopener">https://onlinegdb.com/SJhVBUJU4</a>. If you want to learn more details, please go to buy the book: <a href="https://www.crcpress.com/GPU-Parallel-Program-Development-Using-CUDA/Soyata/p/book/9781498750752" target="_blank" rel="noopener">Tolga Soyata. GPU Parallel Program Development Using CUDA. Chapman and Hall/CRC, 2018.</a></p>
]]></content>
  </entry>
  <entry>
    <title>《计算进化史：改变数学的命运》Note</title>
    <url>/2019/02/11/calculation-revolution-history/</url>
    <content><![CDATA[<p>数学，一个由无数抽象概念组成的集合，一门改变无数人的人生轨迹的课程，一个经常让人感叹“每个符号都认识但连在一起就不认识”的异形怪物，终于在这本书里学会了谦卑，被一个曾经的手下败将改变了命运，它就是“计算”。这本书《计算进化史：改变数学的命运》由法国数学家，逻辑学家，航空安全专家吉尔多维克撰写。同时，这本书也荣获法兰西学术院哲学大奖。因为我自身的学术背景跟计算数学息息相关，所以经常会看一些通识读物。但是去年在读过《微积分的历程：从牛顿到勒贝格》之后，我一度觉得计算跟数学核心的距离越来越远，越来越成为一个被数学家们看不起的“实用工具”。直到看到这本书，它不仅把我的疑虑全部扫除，而且还给我足够的信心：如果没有计算，数学恐怕只能画地为牢，兴许早就被当做希腊或者法国的“传统文化”进入博物馆了。<br><a id="more"></a><br>这本书的核心就是在论述“计算”从数学中产生，到被抽象，再到被推理边缘化，最后绝杀返场的辛酸历史。我们知道，数学里充斥着逻辑推理，很多人都喜欢精巧的推理，特别是在看《福尔摩斯》《狄仁杰系列》的时候，经常对里面一环扣一环的推理拍案惊奇。它就像一座艺术品，少一点显得不严密，多一点又太冗长。这些巧夺天工的艺术品，组成一座座优雅的宫殿，没有一丝烟尘。在很长一段时间里，计算被视为丑陋的锄头而被搁置一边，数学家们竞相追逐的目标就是那一个个晶莹剔透的艺术品，无数大师构建了很多“上帝”级别的蓝图。但是直到有一天，基于逻辑推理的宫殿开始出现裂缝，而此时“计算”从沉睡中被唤醒了。。。</p>
<h2 id="1-从计算到推理的转变"><a href="#1-从计算到推理的转变" class="headerlink" title="1 从计算到推理的转变"></a>1 从计算到推理的转变</h2><p>从一开始，数学其实就是产生于“算学”。出于生存需要，美索不达米亚和埃及的会计师早早就掌握了加减乘除的计算法则， 比如划分田地，分配粮食等等。计算土地和粮食，都是基于有限的数量做计算，但是如果把100平方米，100颗鸡蛋，100根绳子，100个日起日落的共同点拿出来，那就是一个抽象的数字：100。它摆脱了任何物理上的约束，从而可以扩大无穷倍，直到无穷大。2500年前的毕达哥拉斯学派汇集了一群“异想天开”的人，他们不想再受现实的局限，而是想找到那些涉及无穷大的道理。他们在思考一个命题：一个平方数不可能是另一个平方数的2倍。这里面所提到的平方数没有上下界，所以就算找来前1万个自然数做验证，也无法确定命题成立，也许第10001个数就能推翻命题。所以，毕达哥拉斯学派的人一致认为：基于具体数字的有限计算是无法解决涉及到无穷大（或无穷小）的问题的，所以数学要靠逻辑推理来判断。从那以后，他们认为“计算”只要能当做一个工具来解决实际问题就好了，真正的数学肯定是基于逻辑推理的。此后，无数哲学家和数学家们（苏格拉底，亚里士多德，莱布尼兹，罗素，希尔伯特等等）为了追求逻辑中的纯粹性，开始对抽象的概念再进行抽象，用来触碰“天生”（先验）的逻辑，从而诞生了公理化方法。至此猜想-定理-证明成了数学的三座支柱，计算被弃置一旁。</p>
<h2 id="2-公理化和谓词逻辑"><a href="#2-公理化和谓词逻辑" class="headerlink" title="2 公理化和谓词逻辑"></a>2 公理化和谓词逻辑</h2><p>这一部分详细介绍了公理化方法的创立。这一部分非常抽象也很刷新认识。一个例子是在几何中的一条公理“过两点有且只有一条直线”中的很多词，比如“点”，“线”，“面”，“过”完全可以去掉任何现实含义，而抽象成A,B,C,D四个字母，然后之后所有的定理也按照这种方式来推导，不做任何现实意义的解读。这样做的结果居然丝毫不影响构建现在的整个几何学大厦。这个观点一开始让我觉得很疯狂，如果真是这样，那么我们十几年来学过的所有几何定理仅仅是一些字母的排列组合。并且，如果公理改变，那些定理不过是把字母的顺序调一调而已，而且就连精心设计的证明过程，也可以看做恰好能自圆其说的字母组合。这一部分，让我觉得数学的公理化已经完全达到了人类抽象能力的极限，如果一切顺利的话，那么正如希尔伯特畅想的那样，数学的这个房间建好了，大家以后直接登录进来各取所需就好。可惜，丘齐和图灵用“逻辑推理”否定了希尔伯特对“逻辑推理”的畅想，具体的方法涉及到可计算理论和构造性理论，这些都直接导致了计算机的诞生。这里面太过复杂，而且很多概念都上升到了哲学层面（构造主义），实话说，很难通过一本科普级别的书就搞明白，这里就略过。</p>
<h2 id="3-公理化危机"><a href="#3-公理化危机" class="headerlink" title="3 公理化危机"></a>3 公理化危机</h2><p>当公理化无法解决很多问题的时候，计算就又回来了。这里就举一个例子：四色定理的证明。给任何一个地图上色，要求是相接触的图形颜色不同，那么只需要四种颜色就够了。这个问题在1853年提出，25年后有人声称解决了问题，但是10年之后被发现证明有误。直到1976年，开尼斯和沃尔夫冈才借助计算机彻底解决了问题。这个证明的过程的逻辑非常严密，没有漏洞，但是却饱受争议，因为这个证明毫无优雅可言，而且里面使用了简单粗暴的穷举法。通过让计算机连续计算1200个小时来验证1500个结果，一份长达几百万页的机器证明诞生了。没有人能够通读，所以打印也变得毫无意义。为了验证这个证明是否正确，2005年乔治和本杰明写了一个程序验证了之前的机器证明。在这一刻，数学变成了实验科学，以后每一位数学家的手上都将沾满丑陋的计算带来的灰尘。到底数学的未来走向何方？本书的作者认为在未来的某个读者，一定会对20世纪的数学家完全靠手工解决所有问题的历史感到吃惊。</p>
<p>虽然未来不得而知，我作为一个资深的“伪数学迷”，如果每隔一段时间能感受到一些思维冲击就已经很满足了。最后想说一下，本书的作者的头衔起初让我非常不解，因为我无论如何都发现不了“逻辑学家”和“航空安全专家”这两者的联系，一个有关最底层的先验判断，一个是很表面的工程应用，不过在读完书后觉得，其实在一个更广阔的意义上，“逻辑”和“安全”可以划等号，因为逻辑来自于本能的判断，在这种本能的驱使下，前辈们不断地对现状提出质疑并加以修正，才最终让我们的周围看上去那么自恰，由此引发的心理舒适谓之“安全”。再次感谢图灵能引进这本带来思想冲击的书，想看就请购买吧！(<a href="http://www.ituring.com.cn/book/1926" target="_blank" rel="noopener">去买书</a>)</p>
]]></content>
  </entry>
  <entry>
    <title>Burn CPU&#39;s Calories (1)</title>
    <url>/2019/02/10/burn-cpu-calorie-1/</url>
    <content><![CDATA[<p><strong>Q: What are you reading recently?</strong><br>A: <strong><em>GPU Parallel Program Development Using CUDA</em></strong>, written by Professor Tolga Soyata in State University of New York - Albany (SUNY Albany).<br><strong>Q: I know GPU. It is the acronym for graphic processing unit. Nowadays, many huge video games, like Call of Duty, Battlefield 3, Civilization, etc., require some advanced 3D vitualization capabilities by GPU cards, like Nvidia GeForce GTX 1080 Ti. Even for some online games, like Overwatch, a better GPU card can delivery better 3D vision performance. But… how does it relate to programming?</strong><br>A: Your saying is right, but the gaming purpose is only a small portion of the entire GPU world. There are many GPU manufactures, like NVIDIA, AMD, Intel, Asus, etc., with different architectures for various applications and contexts. Here, I only take NVIDIA’s GPUs as an example. It has many different series of GPU cards. Although all NVIDIA GPUs support general purpose computation (GPGPU), different series offer different performance features. The GeForce you mentioned is the series for consumer gaming. The GPUs in the book I read belong to Tesla/Quadro series, which is for high performance scientific computing.<br><strong>Q: I see…but what’s the difference other than the name?</strong><br><a id="more"></a><br>A: There are many differences in various aspects, like floating point capability, error correction, memory, etc, but you can just remember the most evident difference is the price. The price of the latest gaming GPU card, NVIDIA GEFORCE RTX 2080 Ti, is about $1400, while that of Tesla, Nvidia Tesla v100 (16GB), is about $5500.<br><strong>Q: Hahaha, the price is everything! OK…let’s go back to the book. I heard about programming, but what does the “parallel programming” mean?</strong><br>A: This is the key. In fact, because a GPU card normally has thousands of cores, so unlike the serial job running on CPU, the program running on GPU always launches on massive processing units in parallel. Therefore, “parallel programming” means “programming code for executing in parallel”.<br><strong>Q: I see… so the “parallel” here is related to the hardware feature of GPU card. You mentioned about “serial job running on CPU”, but I think that’s not always the case, usually a modern CPU has more than one core, so parallel jobs can also run on CPU, right?</strong><br>A: Correct. For example, my HP ENVY laptop has Intel i7-4700MQ CPU with 4 cores with hyper-threading technique, which allows each core running up to 2 threads at the same time (8 threads in total), but a parallel program requesting 10 threads could still be able to run.<br><strong>Q: I am confused. CPU, GPU, core, thread, task, … so many concepts. Why could the 10-thread code run on a CPU supporting at most 8 threads?</strong><br>A: Don’t worry. This is what this book all about. In the first part, it starts from serial to parallel programming in CPU, which provides a solid basics for operating system, CPU and memory. In the second part, it delivers the previous CPU knowledge to the GPU world, because CPU and GPU are the same in the fundamental level. The whole book is full of sketches, analogies and psudo-codes. It reads like telling a story instead of listing knowledge points. Let’s get started. The sample code in the book is to flip an input image vertically or horizontally. To simplify it, I just use a simple 2D array (matrix) to represent the image. My final target is to maximize the CPU power to accelerate the entire process by applying many programming rules related to hardware, operating system, compiler, memory access, multi-threading techniques and etc.<br><strong>Q: Amazing. Is there any place in which I can access your code?</strong><br>A: I will put some critical code directly in this blog, but the entire source is available at (<a href="https://onlinegdb.com/S1YVv5T4N" target="_blank" rel="noopener">Check the Source!</a>). The initial and trivial implementations of two functions called <strong>FlipMatrixV</strong> and <strong>FlipMatrixH</strong> are shown here:<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> row = <span class="number">12800</span>;</span><br><span class="line"><span class="keyword">int</span> col = <span class="number">9600</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">FlipMatrixV</span><span class="params">(<span class="keyword">int</span> row, <span class="keyword">int</span> col, <span class="keyword">int</span> **matrix)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;col; j++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;row/<span class="number">2</span>;i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> temp = matrix[i][j];</span><br><span class="line">            matrix[i][j] = matrix[row-i<span class="number">-1</span>][j];</span><br><span class="line">            matrix[row-i<span class="number">-1</span>][j] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">FlipMatrixH</span><span class="params">(<span class="keyword">int</span> row, <span class="keyword">int</span> col, <span class="keyword">int</span> **matrix)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;row;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;col/<span class="number">2</span>;j++)&#123;</span><br><span class="line">            <span class="keyword">int</span> temp = matrix[i][j];</span><br><span class="line">            matrix[i][j] = matrix[i][col<span class="number">-1</span>-j];</span><br><span class="line">            matrix[i][col<span class="number">-1</span>-j] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>The wall clock time of executing the above process is<br>
</p><p style="background-color: #000000; color: #00FF00">
Time cost to flip the matrix vertically is 4.80731182e+00 seconds.<br>
Time cost to flip the matrix horizontally is 4.41095461e-01 seconds.<br>
</p>
<br><strong>Q: Why the execution time of horizontal flip is less than 10% of that of vertical flip? The numbers of data movement are the same, right? If I do these two tasks by hand, they would cost similar time for me.</strong><br>A: You are exactly right. The computer doesn’t do things in the exactly same way as human. Don’t worry. The reasons will be explained step by step. I will go back to your problem later. Let’s first focus on the multi-threading technique. The above code is very trivial, so I won’t explain it.<br><strong>Q: OK. I have no experience on multi-threading. I only remember when I was looking around in the computer shop and the sales man advertized the 4 core/8 thread laptop to me. He said that laptop can be treated as an 8-core machine, but only costs money to buy a 4-core machine… then I bought it.</strong><br>A: Hmm…in fact, he was not wrong, but omitted many crucial details to you. In fact, the CPU in your laptop only has 4 <strong>physical cores</strong> and each physical core can run 2 threads simultaneously (so called hyper-threading technology), thus in total 8 threads, which are also called <strong>virtual cores</strong>. An 8-physical-core machine is not identical to an 8-virtual-core machine at all. No free lunch!<br><strong>Q: What’s the difference between the physical cores and virtual cores?</strong><br>A: Hardware resources. A physical core has its individual hardware resources (ALU, FPU, cache, etc), but a virtual core (<strong>hardware thread</strong>) resides into a physical core. It only has own register files and has to share most hardware resources with other virtual cores within the same physical core. Here is a sketch of the architecture of one physical core (2 thread).<p></p>
<p><img src="/images/physical_core_cpu.jpg" alt="Physical_Core"><br>You see. The two threads share all the execution units, instruction and data streams from L1 cache. It is the reason why the hardware threads are called “virtual” cores instead of “real” cores. Imagine two works are manufacturing cellphones, but they have to share their tools, thus one work has to wait for another when the tools are saturated, so the efficiency can not be doubled. Of course, if the two works can arrange their work orders perfectly to avoid the saturation of tools, things will speedup, so that depends.<br><strong>Q: Oh… You should read this book and tell me about this last year before I bought my laptop…</strong><br>A: That’s not too bad. Currently a 8-physical-core machine is very expensive and unnecessary for everyday use.<br><strong>Q: Good. Let’s go back to the multi-threading, so I think it’s about programming to exploit the 2 threads in the physical core, right?</strong><br>A: Not really. To explain the multi-threading programming, we firstly need to make clear that there are two types of “thread”. One is called <strong>hardware thread</strong>, another is…<br><strong>Q: </strong>software thread<strong>?</strong><br>A: Exactly. The “thread” or “virtual core” shown in the above figure is the hardware thread. It is a physical object set in stone by the CPU manufacturer. However, the “thread” in “multi-threading programming” means the software thread, which is usually associated with <strong>task</strong>. One thread is associated with one task. Therefore, “thread” has different meanings in different contexts.<br><strong>Q: I see. but how are they related to eath other? I mean… how could I let multiple tasks (software threads) run on multiple virtual cores (hardware threads)? Are they automatic?</strong><br>A: Good question. In fact, the mapping from software threads to hardware threads are done by operating system automatically. The OS will always try to assign some particular available hardware resources to execute a software thread maximum performance. However, at the same time, the programmer also has to write some codes explicitly to tell the OS to divide the entire job into several child tasks (software threads). This is the meaning of multi-threading programming. Let’s say your laptop has 4C/8T, but if a program is designed to execute on a single virtual core, so about 80% of the hardware resources are wasted. Maybe in 1-2 decades ago, single-core programs were the mainstream, because most CPUs only had one core with single thread at that time. However, nowadays, most manufacturers try to put more and more cores as well as threads to a CPU chip, such as 2C/4T, 4C/8T, 8C/16T, etc.<br><strong>Q: Hmm…why don’t they try to improve the capability of a single core to create a super powerful single-core CPU? If they did that, programmers would not have to learn this multi-threading programming.</strong><br>A: In fact, they can’t. The detailed reasons are complex, which I may explain in another blog, but to be simple, the more powerful a single core is, the smaller inside transistors have to be. The size of transistor is already very close to its physical limitation. Also, another big factor is the drastic growing power consumption with the higher transistor’s frequency. Therefore, you can even notice an interesting phenomenon that many latest CPUs use even lower frequencies but put more virtual cores inside to improve the overall performance.<br><strong>Q: I see… interesting. I also noticed that the CPU frequency doesn’t grow like before nowadays.</strong><br>A: Let’s look at the first example of multi-threading programming. The following code is a function to flip a matrix vertically using multi-threads.<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">MTFlipV</span><span class="params">(<span class="keyword">void</span>* tid)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ts = *((<span class="keyword">int</span>*) tid);</span><br><span class="line">    ts *= col/num_threads;</span><br><span class="line">    <span class="keyword">int</span> te = ts+col/num_threads<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=ts; j&lt;=te; j++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;row/<span class="number">2</span>;i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> temp = matrix[i][j];</span><br><span class="line">            matrix[i][j] = matrix[row-i<span class="number">-1</span>][j];</span><br><span class="line">            matrix[row-i<span class="number">-1</span>][j] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>We can easily see the main body of MTFlipV() is quite similar to its single-thread version FlipMatrixV(). The only difference is that the starting and ending col index are adapted by the index of the corresponding thread. It divides the entire flipping task into several smaller sub-tasks, then assign each sub-task to one thread. Be careful, the “thread” mentioned here means the software thread, which will be assigned to a hardware thread by the operating system in the future. The “tid” (ID of thread) of first thread starts from 0, so it is easy to figure out the above code.</p>
<p>The following code is how to launch the MTFlipV() function using multi-threads via the pthreads library in the main() function. It should be noted that the pthreads library only work in a POSIX-compliant operating system like Linux and MacOS, but not Windows. However, there is a tool called Cygwin64 in windows platform to simulate the POSIX system.<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">pthread_attr_init(&amp;ThAttr);</span><br><span class="line">pthread_attr_setdetachstate(&amp;ThAttr, PTHREAD_CREATE_JOINABLE);</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> a=<span class="number">0</span>;a&lt;REP;a++)&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;num_threads;i++)&#123;</span><br><span class="line">        ThParam[i] = i;</span><br><span class="line">        ThErr = pthread_create(&amp;ThHandle[i], &amp;ThAttr, MTFlipV, (<span class="keyword">void</span>*)&amp;ThParam[i]);</span><br><span class="line">        <span class="keyword">if</span>(ThErr != <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"\nThread Creation Error %d. Exiting abruptly...\n"</span>, ThErr);</span><br><span class="line">            <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_attr_destroy(&amp;ThAttr);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;num_threads;i++)&#123;</span><br><span class="line">        pthread_join(ThHandle[i], <span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>I will not expand the details of pthreads. The key function is pthread_create(), which is reponsible for creating and launching a child thread to execute the assigned function. For the above example code, the target function is MTFlipV() and the corresponding pass-in parameters are stored in ThParam[i] for i-th child thread.<br><strong>Q: I see. I can’t wait to launch this multi-thread code.</strong><br>A: No hurry. I will show some timing results using up to 10 threads (software threads) running on my laptop (4C/8T)!<br>
</p><p style="background-color: #000000; color: #00FF00">
Time cost to flip the matrix vertically (single thread) is 1.89586501e+00 seconds.<br>
Time cost to flip the matrix vertically (num of thread = 2) is 1.04919381e+00 seconds.<br>
Time cost to flip the matrix vertically (num of thread = 3) is 7.11957598e-01 seconds.<br>
Time cost to flip the matrix vertically (num of thread = 4) is 6.40509558e-01 seconds.<br>
Time cost to flip the matrix vertically (num of thread = 5) is 7.42702818e-01 seconds.<br>
Time cost to flip the matrix vertically (num of thread = 6) is 7.46646404e-01 seconds.<br>
Time cost to flip the matrix vertically (num of thread = 7) is 7.15668392e-01 seconds.<br>
Time cost to flip the matrix vertically (num of thread = 8) is 7.39448214e-01 seconds.<br>
Time cost to flip the matrix vertically (num of thread = 9) is 7.71293783e-01 seconds.<br>
Time cost to flip the matrix vertically (num of thread = 10) is 7.7037100e-01 seconds.<br>
</p>
<br>We can see the multi-threading program gets evident speedup indeed!<br><strong>Q: Yes! The 2-thread version gets 1.8X speedup, which is close to the ideal 2X. The 3-thread version gets 2.66X, which is still good. The 4-thread version gets 2.95X, which is more than 50% efficiency and acceptable. However, the 5- or more- thread version costs more than 4-thread, so its extra threads even destroies the 4-thread version’s speedup, why? My second question is that why the 10-thread version doesn’t crash on your 4C/8T laptop? My third question is why the 4-thread version can’t achieve about 4X speedup?</strong><br>A: This is the science as well as the art of multi-thread programming. It usually doesn’t go as expected. All of your three questions are related to some deeper mechanism of computers. To make it short, see you next time!<br><strong>Q: …</strong><p></p>
]]></content>
  </entry>
  <entry>
    <title>微积分的历程--从牛顿到勒贝格</title>
    <url>/2018/07/19/calculus-galary/</url>
    <content><![CDATA[<p>牛顿，一个总结出统治经典物理的力学三定律的先驱，一个发现天体运转规律的预言者，一个耐心地把无穷级数和逆级数玩转的魔术师，一个经常写一个漂亮的公式但就是不说自己是如何得到的怪才，一个把24K纯机械怀表当鸡蛋煮的英国贵族，说：“我只是一个在海边玩耍的小孩，偶尔捡起了几个美丽的贝壳，但是对于真理的大海，我却丝毫没有发现。”我一度觉得这就是牛顿在谦虚，但是看了这本书才发现，如果说牛顿谦虚，那么不仅莱布尼兹会不服，而且在此后的几百年里，伯努利，欧拉，柯西，黎曼，刘维尔，魏尔斯特拉斯，康托尔，沃尔泰拉，贝尔，勒贝格等一大批人先后驾着帆船去与凶险的海浪搏斗，用实际行动告诉了我们牛顿确实没发现真理的大海。这本由美国著名数学作家William Dunham写的《微积分的历程—从牛顿到勒贝格》正是一本记录了微积分发展历程中最精彩事件和最主要定理（含证明过程）的书。第一次在图灵社区看到这本书的时候，看书名以为是一本以记史为主的轻科普书。但在仔细读过第一章之后，就发现这本书其实可以当做半个教材使用了，因为里面的公式和证明都非常详实。这本书依照历史发展的顺序，记录了从微积分这个概念被提出的17世纪60年代到测度论基本建成的20世纪初，这300年之间的思想的起伏。在读这本书的过程中，一开始心里是惴惴不安的，因为这本书居然直接用一些令人瑟瑟发抖的人名作为章节的标题，比如第4章-欧拉，第6章-柯西。不过在深入其中之后，倒是觉得里面的人物变得温和起来，这些大数学家一个个都是有血有肉的人，比如牛顿遇到棘手的问题也会搪塞回避，面对比自己强的竞争对手莱布尼兹也会拉帮结派搞学术政治；伯努利兄弟为了谁先解出难题而耿耿于怀；柯西甚至没有完全理解以自己的名字命名的“柯西序列”（就像鲁迅不会做自己文章的阅读理解一样）等等。这本书是近期读过的最精彩的书，没有之一，对比以前度过的分析学教材，这个是第一本让我能看得懂里面99%证明题目的书，而且深度也是够的。下面就简单回忆一下这本书的内容。<br><a id="more"></a></p>
<h2 id="1-早期"><a href="#1-早期" class="headerlink" title="1. 早期"></a>1. 早期</h2><p>在早期，为了求解曲线下的面积，牛顿、莱布尼兹提出微积分。在那之后，分析学家其实就是无穷级数学家，因为他们都在比谁能把无穷级数这门技术玩到极致。伯努利兄弟接过了恩师莱布尼兹的大旗，同样坚信无穷级数是进入分析学的必由之路。雅各布·伯努利发现了调和级数发散，约翰·伯努利也发现了$x^x$的积分可以表示成一个无穷级数，并且抽空还培养了一位研究生—欧拉同学。欧拉特别喜欢计算积分，当然跟莱布尼兹是一脉相承的，最善于用无穷级数去辅助求各种复杂的积分。这里值得一提的是当无穷级数遇到$\pi$的魔力。我们知道古代中国数学家祖冲之在公元5世纪已经把圆周率精确到了7位小数，然后这个记录被打破是15世纪的阿拉伯数学家—卡西（精确到了17位），前后一共1000年，把精确度推进了10位小数。现在我们把眼光移向欧洲，在16世纪的韦达用正393216多边形把$\pi$精确到了第9位小数，没多久之后依然在16世纪，科伊伦用纯手工计算的方式，用2^62边形把$\pi$精确到了35位小数，这个计算耗费了他一生的时光。他们用的方法都是割圆术，然后到了18世纪，欧拉就用一个无穷级数的简单公式轻松超越了之前所有人，用这个公式计算到第20位小数也就大约1小时，这就是算法的力量。</p>
<h2 id="2-第一次波折"><a href="#2-第一次波折" class="headerlink" title="2. 第一次波折"></a>2. 第一次波折</h2><p>在莱布尼兹发表第一篇微积分论文之后的第99年，欧拉辞世。在这么多位卓越先驱的呵护下发展了近一个世纪的微积分，此时依旧脆弱不堪，很多底层的假设大多依靠直觉而不是推理。牛顿所提出来的“逐渐消失的量”成了各大反对者批评的对象。英国著名的哲学家和克罗因教区的主教—柏克莱写了一篇标题很长的文章，题目是《致一位不信教的数学家的评论，其中剖析现代分析学的目标、原理和结论是否比宗教的神秘和教义有更清晰的构思或更缜密的推理》。很显然，此时的微积分在神学家看来，成为了攻击数学家们的最有力武器。而且这位柏克莱主教说了一句让我拍手称绝的话：“错误也许能产生真理，但是绝不会产生科学”。这也是我认为西方现代科学最美丽的部分，不是只看重某个结果是否正确，而是更关注产生这个结果的过程是否严谨和科学，这保证了科学的每一点进步都是无比坚实的，这也恰恰是东方哲学中最欠缺的。我们知道，当一个东西处于风口浪尖的时候，往往会吸引来一大批关注者，比如拉格朗日就发表过一篇文章，用无穷级数来代替微分，巧妙绕开了“逐渐消失的量”，本来自信满满以为功成名就的时候，遇到了一个柯西举出的反例和质疑，立刻被抛弃。没错，这本书关于拉格朗日这位大数学家的篇幅就这么多，不管他在其他领域的成就多么伟大，在普鲁士科学院的头衔多么高，在微积分底层逻辑构建的大潮中，他只是大胆地做了一次不那么严谨的尝试就被严厉驳倒，在科学面前，人人平等。那么真正迈出坚实第一步的是谁？没错，柯西！</p>
<h2 id="3-攻坚期"><a href="#3-攻坚期" class="headerlink" title="3. 攻坚期"></a>3. 攻坚期</h2><p>19世纪的柯西，用精湛的手法证明了介值定理、中值定理以及微积分的基本定理，而且找到了两个很具体的级数收敛判别法则。更重要的是，他第一次明确了积分学相对于微分学的独立地位，这一点是欧拉所没有认识到的。事实上，当我读到柯西的时候，感觉他并没有提出多少惊世骇俗的新概念，但是作者也说这一章的篇幅却是最长的。我觉得，数学的发展或许可以分成两类，第一类是像牛顿、莱布尼兹一样，提出新概念的轮廓，让人们心之向往；第二类是像柯西这样，对一个模糊的轮廓进行精确的刻画，让人们能触摸到每一处纹理。这两类的贡献，缺一不可，柯西的贡献绝对是不亚于牛顿的。在柯西确立了积分独立地位之后，随着对严密性研究的深入，曲线的几何直观越来越被淡化，取而代之的是抽象的函数，并且函数的样子越来越奇特。比如狄利克雷函数，在实数上处处不连续，如何定义积分？柯西的定义法此时就不行了，这个时候黎曼站了出来，提出了黎曼可积性的充分必要条件（证明过程很精彩），证明狄利克雷函数不可积，因为它‘太’不连续了。大家都知道，数学家不喜欢用‘太’‘很’这样的词，因为不够定量，他们总是希望得到一个可以测量的指标来说明问题，所以这里就引申出来一个核心问题：到底一个函数不连续到什么程度才会变得不可积？这个问题，要到50年之后，勒贝格站在黎曼这个巨人的肩膀上才得以攻克。那么在这50年之间，数学家们也没有闲着。前面说的都是等式，刘维尔通过一个不等式，发现了无理数与有理数之间的空隙，并且通过亲手构造了一个超越数而证明了超越数的存在。威尔斯特拉斯更是励志典型，从中学教师一路干到柏林大学教授，然后被黄袍加身成为“现代分析学之父”。他从点态极限的缺陷中，提出了一致收敛的概念。在1875年，提出的一个处处连续却无处可微的函数，颠覆了所有人的认识，很多数学家纷纷表示要重塑三观。如果当时有网络自媒体，那么文章标题一定是“震惊！前中学数学老师竟然做出这种事，查尔斯·艾尔米特看了沉默，亨利·庞加莱看了流泪”。</p>
<h2 id="4-第二次波折"><a href="#4-第二次波折" class="headerlink" title="4. 第二次波折"></a>4. 第二次波折</h2><p>随着微积分越来越严密，人们构造了大量的不同不连续程度的函数，并且验证了其可积性，似乎之前那个函数可积性问题的答案越来越呼之欲出了，但就是没有捅破最后那一层窗户纸。最沉闷的时刻不过如此，保罗·杜布瓦·雷蒙认为黎曼的定义无法再改进了，于是他止步于此；而康托尔则另辟蹊径，从集合论的观点出发，掀起了一场现代革命。</p>
<h2 id="5-集合论与测度论"><a href="#5-集合论与测度论" class="headerlink" title="5. 集合论与测度论"></a>5. 集合论与测度论</h2><p>出生于音乐世家而具备浪漫主义情怀的康托尔，一直都在追求数学中超然的自主性。他发现了区间的不可数性，从而立刻证明了超越数的存在，并且因为超越数的不可数性，其数量远大于可数的代数数。这里康托尔与刘维尔形成了鲜明的对比。作者的一个比喻非常精彩，他说刘维尔就像一个勤劳的老农，在一片甘草堆里四处翻找，突然一根针刺痛了他的手指，他才发现原来还有针的存在。而康托尔只是轻松地变个魔术把你带到夜空下，让你看到代数数只是夜幕下的点点繁星，超越数才是浓黑的万里长空。接下来有了集合论这个手段，沃尔泰拉和贝尔对集合的稠密性，连续性与稠密性的关系进行了，函数的分类等问题进行了一系列探索，而这些所有数学家们的成果都成为了勒贝格的垫脚石。他提出的测度论一举解答了50年来困扰数学界的难题：黎曼可积性的充分必要条件是不连续点的集合具有零测度。在回答完这个问题后，他没有就此满足，在彻底理解了黎曼积分之后立刻放下了黎曼积分，把目光投向远方，提出了勒贝格积分，完美地证明了300年前牛顿和莱布尼兹提出的微积分基本定理，至此最后一块拼图也贴好了。无数的数学家们用300年的时间在外面兜兜转转，最后又回到起点。从肯定到否定，再到否定之否定，微积分的发展作为哲学课程的典型再好不过。</p>
<p>尾注：现代微积分教材中广泛使用的$\int$是莱布尼兹发明的，$f^{\prime}$是拉格朗日发明的，但是在书中的篇幅并不多，因为前者遇到了牛顿，后者遇到了柯西。</p>
<p>感谢图灵能引进这本让人酣畅淋漓的书，想看就请购买吧，如果不在中国，也有kindle电子版：(<a href="http://www.ituring.com.cn/book/147" target="_blank" rel="noopener">去买书</a>)</p>
<p><img src="/images/calculus.PNG" alt="title"></p>
]]></content>
  </entry>
  <entry>
    <title>Scientific Software Development I</title>
    <url>/2018/04/15/sci-soft-dev-1/</url>
    <content><![CDATA[<p><strong>Q: What are you doing recently?</strong><br>A: I am doing some scientific programming.<br><strong>Q: I hear about some programming languages, like C/C++, Java, Python, and so on. But could you tell me what’s the difference between the general purposed programming and scientific programming?</strong><br>A: In short, more extensive arithmetic operations on real numbers, which is represented by a number of floating point type in computers.<br><strong>Q: I think if the floating number can be represented in computers, there should not be too much difference from integer, right?</strong><br>A: Problems come here. Computer can’t represent a general real number in an exact manner. For irrational number, of course, we can only use an approximated number with its several leading digits. However, even for rational numbers, we can only use an approximation.<br><strong>Q: What kind of approximation? Or what’s the error?</strong><br>A: It depends. There are several types of floating point number: single-precision, double-precision and extended precision (IEEE 754 Standard). They have different level of accuracy. Look at this table</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Tables</th>
<th style="text-align:center">unit round-off</th>
<th style="text-align:center">max number</th>
<th style="text-align:center">bits</th>
</tr>
</thead>
<tbody>
<tr>
<td>single-precision</td>
<td style="text-align:center">6.e-8</td>
<td style="text-align:center">10^38</td>
<td style="text-align:center">32</td>
</tr>
<tr>
<td>double-precision</td>
<td style="text-align:center">2.e-16</td>
<td style="text-align:center">10^308</td>
<td style="text-align:center">64</td>
</tr>
<tr>
<td>extended-precision</td>
<td style="text-align:center">5e-20</td>
<td style="text-align:center">10^9863</td>
<td style="text-align:center">80</td>
</tr>
</tbody>
</table>
</div>
<a id="more"></a>
<p><strong>Q: What’s the difficulty?</strong><br>A: In most general purposed programming, the logic operations are dominated, but for scientific programming, we do lots of arithmetic calculations, which may cause many problems, like NAN (not a number). Its occurrence is due to undefined operation, like 0/0, Inf/Inf, Inf-Inf, sqrt(-1), log(-1), etc.<br><strong>Q: How can I detect a NAN number?</strong><br>A: From the IEEE Standard, the NAN is the only floating point number which is not equal to itself. If $x==x$ fails, it must be a NAN.<br><strong>Q: What’s the most common arithmetic computation?</strong><br>A: Solve the linear equation $Ax=b$ efficiently.<br><strong>Q: <span>$x=A^{-1}*b$</span><!-- Has MathJax -->, right?</strong><br>A: Right, but in numerical computation, you can’t get an exact inverse of A. Sometimes, the error is enormous. It can be indicated by the condition number of A, which indicates the error sensitivity of the matrix. This is why people use some precondition process to make the system to be well-conditioned.<br><strong>Q: Ok, maybe too much mathematics for me. Let’s talk about programming more. What language do you use to do your scientific computation?</strong><br>A: C/C++ and Matlab.<br><strong>Q: Why not Java? I think it is more popular in IT industry.</strong><br>A: The efficiency is not that high. I know there are at least two factors. First, Java is an intermediate language between compiled and interpreted languages. The source code written in Java will be compiled into ‘bytecode’ first and then interpreted by Java virtual machine (JVM). This interpretation will reduce the execution speed. The second thing is Java provides garbage collection. It’s a very user-friendly feature to avoid nearly 99.99% memory problems, but the price is to cost more. C/C++ is a completely compiled language and the garbage collection is handled by the developer themselves.<br><strong>Q: OK, I see. But why not Fortran? I know many scientists are using Fortran 2003, which provides OOP features also.</strong><br>A: I do not know much about Fortran 2003. It has some good features, like good compatibility with C (e.g. C_INT, C_FLOAT…). Maybe it is also related with many factors, like the history, software environment, etc. For languages themselves, C/C++ passes the arguments by value (copy the value of args onto the stack), but Fortran passes the arguments by reference (put the address of args onto the stack). Also for “multi-dimensional array”, C/C++ uses row-major storage order, but Fortran uses column-major order. There is no any preference for computers, but for developers with different habits, it really matters.<br><strong>Q: I see. Why you use quotation marks for “multi-dimensional array”?</strong><br>A: Fortran supports 2D array intrinsically, but C/C++ only has 1D array. The 2D array is represented by a 1D array of some 1D arrays.<br><strong>Q: You say developers with different habits would prefer C/C++ or Fortran, why?</strong><br>A: It relates with the efficiency of memory access. For example, if you want to do a matrix-vector multiplication. A is $m \times n$. For C/C++, the most efficient way is<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;m;i++)</span><br><span class="line">  y[i]=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;n;j++)</span><br><span class="line">  y[i] += A[i][j]*x[j]</span><br></pre></td></tr></table></figure><br>For Fortran, the most efficient way is<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;m;i++)</span><br><span class="line">  y[i]=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span>(j=<span class="number">0</span>;j&lt;n;j++)</span><br><span class="line">  <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;m;i++)</span><br><span class="line">    y[i] += A[i][j]*x[j]</span><br></pre></td></tr></table></figure><br><strong>Q: Why is reading the adjacent memory more efficient?</strong><br>A: It relates with the mechanism of computer’s memory. The big picture is when the CPU wants to process some data from memory, it will grab a block a memory containing those data into register and caches. The data access in register and cache is much faster than that in main memory. Look at the structure and the table<br>Register&lt;—&gt;L1 cache&lt;—&gt;L2 cache&lt;—&gt;main memory</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Pentium 4 CPU</th>
<th style="text-align:center">Register</th>
<th style="text-align:center">L1 cache</th>
<th style="text-align:center">L2 cache</th>
<th style="text-align:center">main memory</th>
</tr>
</thead>
<tbody>
<tr>
<td>access cost(ns)</td>
<td style="text-align:center">0.4</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">8.0</td>
<td style="text-align:center">150</td>
</tr>
</tbody>
</table>
</div>
<p>If the CPU can read the nearby data from register, the data access is 300X faster than grabbing it from main memory.<br><strong>Q: What a huge advantage!</strong><br>A: Yes. If a programmer likes row-major storage order, using Fortran will be a nightmare, and vice versa.<br><strong>Q: You mention about the memory. I wonder how the variables are stored in the memory?</strong><br>A: In fact, you can refer to my previous blog <a href="http://cfdplay.com/2017/12/08/c-pointer-20171209/" target="_blank" rel="noopener">Here</a>. The allocating variables are stored in three regions: stack, fixed memory location and heap. The stack stores the local variables, which will be eliminated automatically when the function returns. The fixed memory location stores the global variables to be used by several different subroutines. Moreover, the local static variables are also here. The heap is good for storing large objects. When you use malloc or new, it tries to find a block of free memory and return a pointer to the start of that block of memory.<br><strong>Q: The heap sounds cool. If I <span>$malloc(10*sizeof(double))$</span><!-- Has MathJax -->, so it will find a block of <span>$8\times10=80$</span><!-- Has MathJax --> byte?</strong><br>A: Not really. In fact, the block is a little larger than 80 bytes, because for each block, it needs a small header to store the related information usually before the content block, like array size, which is used for deallocation, otherwise, the system doesn’t know how many bytes will be freed.<br><strong>Q: Heap is smart. I wonder how the system finds the proper free block? Just scan the memory directly? That will be too expensive, right?</strong><br>A: Good question. In fact, to facilitate this kind of searching, a memory heap may maintain two linked lists of pointers to blocks of memory. One (allocated list) contains the pointers to blocks of allocated memory, and the other (free list) contains the pointers to blocks of free memory.<br><strong>Q: Heap is very smart. Should we use heap as possible as we can?</strong><br>A: No. The allocation and deallocation have some overhead. That is to say, in a short and extensively repeated function, try to avoid using heap memory. The heap is good for large objects which have relatively long lifecycles.<br><strong>Q: Hmm, reasonable. In a previous question, I forget to ask. You say the C/C++ does not support 2D array, which is treated as 1D array of 1D array. For example, if I declare a dynamic “2D array”: A[10][20], the A[0][:] and A[1][:] may not locate at contiguous memory location.</strong><br>A: Exactly. You are right. The consecutive allocation calls can’t guarantee the memory is contiguous.<br><strong>Q: What a sad thing…</strong><br>A: Wait, there is still a trick to satisfy your expectation. See this:<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">A = (<span class="keyword">double</span>**) <span class="built_in">malloc</span>(m*<span class="keyword">sizeof</span>(<span class="keyword">double</span>*))</span><br><span class="line">A[<span class="number">0</span>] = (<span class="keyword">double</span>*) <span class="built_in">malloc</span>(m*n*<span class="keyword">sizeof</span>(<span class="keyword">double</span>))</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;m;i++)</span><br><span class="line">  A[i] = A[<span class="number">0</span>]+i*n</span><br></pre></td></tr></table></figure><br>A: Exactly. The contiguous allocation in heap memory will not only enhance the data access speed, but also avoid memory fragmentation. Just imagine that a heap, cut into 10K small blocks, is much less efficient than a heap, which is cut into 10 large blocks.<br><strong>Q: Great! What else do you use to increase the efficiency?</strong><br>A: Not many. I still need to go deeper in this topics. There are many good books about efficient memory, which I have not read yet. You may also hear that C++ is slower than C. Programmers should avoid excessive object creation and destruction by using the reference of the arguments, like:<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">func</span><span class="params">(<span class="keyword">const</span> Object &amp;y)</span> <span class="keyword">const</span></span>;</span><br></pre></td></tr></table></figure><br>Also, using inline functions can reduce the function call overhead. In fact, the efficiency is highly related with locality. There are two types of locality: temporal locality (executed code) and spatial locality (data distribution). The row-major and column-major order is a good example of spatial locality. For the temporal locality, try to reduce function calls, which normally lead to setting up of stack frames.<br><strong>Q: What’s the cost of the various arithmetic operations?</strong><br>A: plus and minus cost 1 clock cycle. Multiplication costs 1~2 cycles. Divide costs about 26 cycles. Try to use less divide. Use <span>$x*0.5$</span><!-- Has MathJax --> instead of <span>$x/2$</span><!-- Has MathJax -->.<br><strong>Q: Wow, you need to remember all of the above tips when you are programming? That’s a huge burden!</strong><br>A: Not really. The modern compiler becomes stronger and stronger. It already do many optimizations for us, e.g.<br>(1)    Common sub-expression elimination<br>(2)    Code hoisting<br>(3)    Dead code elimination<br>(4)    Code inlining<br>(5)    Register allocation<br>(6)    Strength reduction<br>Here I will give an example of Code hoisting. The original source code is<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i,j;</span><br><span class="line"><span class="keyword">double</span> sum=<span class="number">0.</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;m;i++)</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;n;j++)</span><br><span class="line">      sum+=A-&gt;me[i][j];</span><br></pre></td></tr></table></figure><br>After the optimization by compiler, the code will be<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i,j;</span><br><span class="line"><span class="keyword">double</span> sum=<span class="number">0.</span>, **A_me, *A_me_i;</span><br><span class="line">A_me = A-&gt;me;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;mi++)&#123;</span><br><span class="line">    A_me_i = A_me[i];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;n;j++)</span><br><span class="line">      sum += A_me_i[j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>The compiler will remove the quantities that are independent of the loop index out from the loop. The orignal source has 2 memory address computation and 3 memory access for each increament, but the optimized version only has 1 memory address computation and 1 memory access. Developers do not have to worry about this kind of optimization.<br><strong>Q: With these wonderful skills as well as tricks, I believe you can develop very fast.</strong><br>A: Not really. Software development is an endless cycle. Look at this<br><img src="/images/soft_dev_cycle.png" width="300px" height="200px"><br>Q: Maybe I have bothered you too much.<br>A: Doesn’t matter, I need to take a rest apart from the design, test, debug and use.<br>Q/A: See you next time!<br><strong>Reference</strong><br><a href="https://www.amazon.com/Writing-Scientific-Software-Guide-Style/dp/0521675952/ref=mt_paperback?_encoding=UTF8&amp;me=" target="_blank" rel="noopener">Oliveira, Suely, and David E. Stewart. Writing Scientific Software: a guide to good style. Cambridge University Press, 2006.</a></p>
]]></content>
  </entry>
  <entry>
    <title>《数学女孩1|2|3》</title>
    <url>/2018/04/07/mathgirl123-cn/</url>
    <content><![CDATA[<p>我是从图灵社区那里偶然看到《数学女孩》这套书的。当时看到的是第一部，刚翻了几页就觉得有意思，就立刻扫码购买了。这本书里面写的是几个日本中学生的日常学习（80%）和生活（20%），除了男主（高二）之外，还有三个女主，分别是同级的高中生米尔嘉，高一的泰朵拉，还有读初中（还是小学？）的远房表妹尤里。米尔嘉是个bug级的存在，作为一个高中生就已经参加国际数学会议，能听懂大部分内容，并且已经预定了去普林斯顿大学主修数学。男主的设定比较符合大部分人的水平，基础不错，逻辑性也较强。泰朵拉一开始特别惧怕数学，在数学学习上总是不得要领，不过在大家的帮助下，快速进步，达到了跟男主相似的水平。尤里是初中生，第三部里才进来，水平肯定不及其他三位，不过她属于那种非常善于思考的类型，有时候提出的数学问题，甚至能给其他人带来灵感和启发。所有的故事都是围绕他们四个人在学习数学中遇到的问题而展开，逐步深入，通过他们的谈话来引出一个又一个数学知识，让读者看到了他们面对数学时的热情，迷茫，偶尔犯晕与最后的自信满满。这也正是这个系列最吸引人的地方，它让我看到的不是像高斯、牛顿、爱因斯坦那种大神级别的人物，高高在上地向大众阐述着世界的真理。这个系列让我看到的是他们四个相互帮助并一起成长的过程。主人公们犯过错误，也走过弯路，但从他们的喜怒哀乐中，让我仿佛看到了曾经的自己，这无疑拉近了作者与读者的距离。<br><a id="more"></a><br><img src="/images/mathgirls.jpg" alt="Memory_overview"><br>这个系列的作者是日本的程序员结城浩(Hiroshi Yuki)。写过程序的人都应该知道，编程其实是一件很耗时间和精力的事情，结城浩能在工作之余依然高产地写作，让我心生敬佩。目前日文版已经出在了第六部，多亏图灵社区的努力，前三部都有了中文版。前几天看到第四部也在翻译中。作者在后记中也说没想到会有这么大的反响，才决定出后续的几部，所以第一部没有副标题，第二部的副标题是费马大定理，第三部的副标题是哥德尔不完备性定理。每一部之间没有硬性关联，不过基本上里面涉及到概念是由浅到深的。说也惭愧，我虽然接受过大学高等教育，但是当看到第二部结尾部分的费马大定理的证明轮廓时就已经非常迷糊讲了，没有完全看明白。唯一的收获是看明白了一个费马大定理n=4时的一个特例的证明，也算是一种自我安慰。第三部的难度就已经很明显了，最后一章已经脱离了科普的范围，而是完全按照哥德尔博士的论文把哥德尔不完备性定理分成几十个小定理和定义去逐步证明和理解，我完全跳过了最后一章。作者结城浩在后记里也坦承，为弄懂哥德尔不完备性定理付出了巨大努力，自己阅读数理逻辑方面的教材，请教很多数学教授，前前后后花了一年的时间才写完第三部，这种为了解决难题而不断寻找解决方法的精神，值得我学习。</p>
<p>由于时间关系，这里我就不展开说了，只列举几个给我留下比较深刻印象的部分：</p>
<p><strong>第一部：</strong><br><strong>1. 证明质数有无穷多个。</strong><br><strong>第二部：</strong><br><strong>2. 群、环、域的由来 （让我明白，数学就是抽象，抽象，再抽象！）</strong><br><strong>3. 阿贝尔群</strong><br><strong>4. 费马大定理n=4的特例证明居然跟一个定理有关“不存在三边皆为自然数，而面积为平方数的直角三角形”</strong><br><strong>第三部：</strong><br><strong>5. 戴德金认为，整体和部分之间存在双向映射代表无限集合</strong><br><strong>6. 皮亚诺算术公理</strong><br><strong>7. 罗素悖论{x|x not belongs to x}是否是自身的元素</strong><br><strong>8. 有理数集是可数集</strong><br><strong>9. 实数集是不可数集（康托尔对角证明法）</strong><br><strong>10. 哥德尔第一不完备性定理: 满足相容、蕴含皮亚诺算术公理且可递归的形式系统，不存在A和非A的形式证明</strong><br><strong>11.  哥德尔第二不完备性定理：在满足上面条件的形式系统中，无法证明自身的相容性。所以如果想证明某个形式系统相容，就需要一个更‘强’的系统来证明它。</strong></p>
<p>时间有限，就写这么多，总之虽然没完全搞懂里面的知识，但是其探索精神是领略到了（这是让我跳过不懂部分的绝佳理由）。唯一让我不满意的是，三部下来，竟然只有男主在原地踏步！其他人都像坐着直升飞机在进步，比如第一部里米尔嘉像一个大学生的水平，第二部里像研究生，第三部里直接参加国际会议，转学去普林斯顿主修数学，快能跟跟数学家谈笑风生了。再比如第一部里泰朵拉最开始连左右极限都不懂，男主还颇有优越感地给她解释，在第二部里发现泰朵拉比自己更快地找到了一个问题的解法而开始怀疑自己，到第三部里，男主貌似也接受了被泰朵拉赶超的事实。尤里的进步无疑是最大的，因为本身几乎没有数学基础，到最后居然也在跟米尔嘉讨论哥德尔不完备性定理，让我觉得不可思议。也许这正是这本书叫《数学女孩》的原因吧，男主是用来用来衬托女孩们的进步的。</p>
<p>最后套用一句最让我觉得好笑的话来结束，第三部里的尤里说“数学书里经常有用于检查视力的符号（这里指存在符号<span>$\exists$</span><!-- Has MathJax -->）。”那么为了学好数学，我要去做眼保健操了，再见！哦，最后附上图书的链接：<br><a href="http://www.ituring.com.cn/book/1675" target="_blank" rel="noopener">数学女孩 1</a><br><a href="http://www.ituring.com.cn/book/1677" target="_blank" rel="noopener">数学女孩 2</a><br><a href="http://www.ituring.com.cn/book/1859" target="_blank" rel="noopener">数学女孩 3</a></p>
]]></content>
  </entry>
  <entry>
    <title>My Q&amp;A on MPI (2)</title>
    <url>/2018/04/07/mpi-2/</url>
    <content><![CDATA[<p><strong>Q: What did we talk about last time? Could you do a brief summary?</strong><br>A: Last time, we mentioned about the 4 send modes (standard, synchronous, buffered and ready). We also tested the MPI_Issend() and found it is not always synchronous although the function name contains a ‘s’ representing it should be synchronous. Some concepts are clarified, e.g. ‘local/nonlocal send-completion’, ‘send-return’. The non-blocking is mentioned a little bit.</p>
<p><strong>Q: Good. I think if I can design the code very well, I do not need the non-blocking communication, right?</strong><br>A: Yes, theoretically you can, but it’s very hard for complex communication context. To avoid many design issues or deadlock, I prefer the non-blocking operations, not only for the simpler design, but sometimes, the efficiency is much better than the blocking counterparts.</p>
<p><strong>Q: I know the non-blocking send is MPI_Isend(), right?</strong><br>A: Right, but not complete. In fact, the non-blocking send also has 4 modes (standard, synchronous, buffered and ready). Last time, in fact, I talked about the non-blocking synchronous send — MPI_Issend(). They are very similar. The difference from blocking send is MPI_I*send() will return immediately.</p>
<p><strong>Q: Are the blocking and non-blocking send and receive compatible with each other?</strong><br>A: Yes. You can use blocking send to send the data out and the data can be received by a non-blocking receive, and vice versa.<br><a id="more"></a><br><strong>Q: In syntax, what’s the most evident difference between the MPI_Send() and MPI_Isend()?</strong><br>A: Here I put the MPI Standard 3.0 here:<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Blocking send</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Send</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, MPI_Datatype datatype, <span class="keyword">int</span> dest, <span class="keyword">int</span> tag, MPI_Comm comm)</span></span></span><br><span class="line"><span class="function"><span class="comment">// Non-blocking send</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Isend</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, MPI_Datatype datatype, <span class="keyword">int</span> dest, <span class="keyword">int</span> tag, MPI_Comm comm, MPI_Request *request)</span></span></span><br></pre></td></tr></table></figure><br>We can see there is an extra argument of MPI_Isend(), it’s type is MPI_Request.<br><strong>Q: What’s the MPI_Request type?</strong><br>A: The MPI_Request is an type for non-blocking communication. It contains some information about the communication associated with this request. Unlike the blocking operator, once it’s returned, the send-buffer is released and ready to be reused. The return of non-blocking operator means nothing, user needs some thing (here the request handle) to track the status of the communication. There is a function named “MPI_Request_get_status()” to let the user to check the status through the request object.</p>
<p><strong>Q: You say the MPI_Request is like a tracker. It means the some variables inside this object wil change with the different communication stages. I think the default/initial value is important because it must represent some default/initial status, right?</strong><br>A: Good question. In fact, the default value of MPI_Request is not defined. In my computer, it is 0. It is better to set it to be MPI_REQUEST_NULL if necessary. It is a constant number defined in mpi.h file. In the mpich 3.0.2 version, it is<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//line 318: </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MPI_REQUEST_NULL   ((MPI_Request)0x2c000000)</span></span><br></pre></td></tr></table></figure><br>After the tracking is finished, the object needs to be reset(freed) to be MPI_REQUEST_NULL by system or the user.</p>
<p><strong>Q: What will happen if I track a MPI_Request object with value of MPI_REQUEST_NULL?</strong><br>A: The monitoring flag will be true, which means the request is complete. It sounds weired because how can the tracker report ‘successful’ with a empty request. In fact, it is very useful in some complex situations to make the code more symmetric. You will discover this feature in the future by yourself.</p>
<p><strong>Q: How to release/free the MPI_Request object?</strong><br>A: If you use MPI_Wait(), it will be freed by the system automatically. If you use MPI_Test(), unless the communication is finished (flag=true), the request will not be freed. If user wants to free it, just use MPI_Request_free(). Here is the code:<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"mpi.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> a[<span class="number">10</span>];</span><br><span class="line">    MPI_Status status;</span><br><span class="line">    MPI_Request s_req;</span><br><span class="line">    <span class="keyword">int</span> got;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> rank, <span class="built_in">size</span>;</span><br><span class="line">    MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(rank==<span class="number">0</span>)&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;<span class="number">10</span>;j++)&#123;</span><br><span class="line">            a[j] = j*<span class="number">0.1</span>+<span class="number">2.13</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"The constant MPI_REQUEST_NULL is "</span>&lt;&lt;MPI_REQUEST_NULL&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        </span><br><span class="line">        MPI_Issend(a, <span class="number">10</span>, MPI_DOUBLE, <span class="number">1</span>,<span class="number">0</span>,MPI_COMM_WORLD, &amp;s_req);</span><br><span class="line">        </span><br><span class="line">        MPI_Request_free(&amp;s_req);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(s_req == MPI_REQUEST_NULL)&#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">"The s_req is MPI_REQUEST_NULL"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">"The s_req is not MPI_REQUEST_NULL"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">do</span>&#123;</span><br><span class="line">            MPI_Test(&amp;s_req,&amp;got,&amp;status);</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">"got is "</span>&lt;&lt;got&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        &#125;<span class="keyword">while</span>(!got);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(s_req == MPI_REQUEST_NULL)&#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">"The s_req is MPI_REQUEST_NULL"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">"The s_req is not MPI_REQUEST_NULL"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(rank==<span class="number">1</span>)&#123;</span><br><span class="line">        usleep(<span class="number">2e6</span>);</span><br><span class="line">        MPI_Recv(a, <span class="number">10</span>, MPI_DOUBLE, <span class="number">0</span>,<span class="number">0</span>,MPI_COMM_WORLD, &amp;status);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">"a["</span>&lt;&lt;i&lt;&lt;<span class="string">"]="</span>&lt;&lt;a[i]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>The output is<br>
</p><p style="background-color: #000000; color: #00FF00">
The constant MPI_REQUEST_NULL is 738197504<br>
The s_req is MPI_REQUEST_NULL<br>
got is 1<br>
The s_req is MPI_REQUEST_NULL<br>
a[0]=2.13<br>
a[1]=2.23<br>
a[2]=2.33<br>
a[3]=2.43<br>
a[4]=2.53<br>
a[5]=2.63<br>
a[6]=2.73<br>
a[7]=2.83<br>
a[8]=2.93<br>
a[9]=3.03<br>
</p>
<br>We can notice that even the request object is freed immediately after the MPI_Issend() before the receiver starts to receive data, the communication will not fail. The ‘tracker’ will not influence the communication itself.<p></p>
<p><strong>Q: The non-blocking mode is much flexible than the blocking mode. Now I want to gather some data from N processors, I need to call (N-1) times MPI_Irecv()?</strong><br>A: No. MPI has the collective communication functions. Here I will only put one which I think the most practical and a little complex. It is MPI_Gatherv():<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"mpi.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">position</span>, i;</span><br><span class="line">    <span class="keyword">double</span> send[<span class="number">3</span>];</span><br><span class="line">    <span class="keyword">double</span> recv[<span class="number">6</span>];</span><br><span class="line">    MPI_Status status;</span><br><span class="line">    <span class="keyword">int</span> disp[<span class="number">3</span>]=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> count[<span class="number">3</span>]=&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> rank, <span class="built_in">size</span>;</span><br><span class="line">    MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);</span><br><span class="line">    <span class="keyword">int</span> nsend;</span><br><span class="line">    <span class="keyword">if</span>(rank == <span class="number">0</span>)&#123;</span><br><span class="line">        send[<span class="number">0</span>]=<span class="number">1.0</span>;</span><br><span class="line">        nsend=<span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(rank == <span class="number">1</span>)&#123;</span><br><span class="line">        send[<span class="number">0</span>]=<span class="number">2.0</span>;</span><br><span class="line">        send[<span class="number">1</span>]=<span class="number">3.0</span>;</span><br><span class="line">        nsend=<span class="number">2</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(rank == <span class="number">2</span>)&#123;</span><br><span class="line">        send[<span class="number">0</span>]=<span class="number">4.0</span>;</span><br><span class="line">        send[<span class="number">1</span>]=<span class="number">5.0</span>;</span><br><span class="line">        send[<span class="number">2</span>]=<span class="number">6.0</span>;</span><br><span class="line">        nsend=<span class="number">3</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    MPI_Gatherv(send, nsend,MPI_DOUBLE, recv,count,disp,MPI_DOUBLE,<span class="number">0</span>,MPI_COMM_WORLD);</span><br><span class="line">    <span class="keyword">if</span>(rank==<span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">6</span>;i++)&#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">"recv["</span>&lt;&lt;i&lt;&lt;<span class="string">"]="</span>&lt;&lt;recv[i]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>
</p><p style="background-color: #000000; color: #00FF00">
recv[0]=1<br>
recv[1]=2<br>
recv[2]=3<br>
recv[3]=4<br>
recv[4]=5<br>
recv[5]=6<br>
</p>
<br>We can see the proc 0 is the root. Proc 0,1,2 will send different sized data to the root. Each procs prepare the pointer of the send buffer as well as the data count. The ‘recv’, ‘count’, ‘disp’ are only meaningful for the root processor. The ‘count’ and ‘disp’ are both arrays.<p></p>
<p><strong>Q: Nice, the collective communication saves me much energy. Does it have any drawbacks?</strong><br>A: It is not flexible. Every processors in the MPI_COMM_WORLD must execute this operator. If you only want the data from the processors with odd ranks, you can not use it directly. Of course, you can always use the send/recv to communicate, but if we want to use the collective communication, we should first put those odd ranks together (maybe create a new group or set to store those ranks) and then call thie collective communication within this group. This capability is also a part of MPI Standard, which will be talked about next time.</p>
<p><strong>Q: Up to now, all the data for communication is just the basic datatypes, e.g. integer, float number, character…, could we communicate the user-defined structure directly between processors?</strong><br>A: The short answer is NO. Any information must be transformed into several MPI datatypes before communication. However, MPI provides the user a better way to ‘pack’ the user’s own structured data. They are MPI_Pack() and MPI_Unpack(). Each pack can have different types of data. It is not used intensively, here I give the code directly.<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"mpi.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">position</span>, i;</span><br><span class="line">    <span class="keyword">double</span> a[<span class="number">10</span>];</span><br><span class="line">    <span class="keyword">char</span> buff[<span class="number">1000</span>];</span><br><span class="line">    MPI_Status status;</span><br><span class="line">    <span class="keyword">int</span> rank, <span class="built_in">size</span>;</span><br><span class="line">    MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);</span><br><span class="line">    <span class="keyword">if</span>(rank==<span class="number">0</span>)&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;<span class="number">10</span>;j++)&#123;</span><br><span class="line">            a[j] = j*<span class="number">0.1</span>+<span class="number">2.13</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> len[<span class="number">2</span>];</span><br><span class="line">        MPI_Aint disp[<span class="number">2</span>];</span><br><span class="line">        MPI_Datatype type[<span class="number">2</span>], newtype;</span><br><span class="line">        i=<span class="number">9527</span>;</span><br><span class="line">        len[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        len[<span class="number">1</span>] = <span class="number">10</span>;</span><br><span class="line">        MPI_Address(&amp;i, disp);</span><br><span class="line">        MPI_Address(a,  disp+<span class="number">1</span>);</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"Proc 0: the address of i is "</span>&lt;&lt;disp[<span class="number">0</span>]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"Proc 0: the address of a is "</span>&lt;&lt;disp[<span class="number">1</span>]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        type[<span class="number">0</span>] = MPI_INT;</span><br><span class="line">        type[<span class="number">1</span>] = MPI_DOUBLE;</span><br><span class="line">        MPI_Type_struct(<span class="number">2</span>, len, disp, type, &amp;newtype);</span><br><span class="line">        MPI_Type_commit(&amp;newtype);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> psize = <span class="number">0</span>;</span><br><span class="line">        MPI_Pack_size(<span class="number">1</span>, newtype, MPI_COMM_WORLD, &amp;psize);</span><br><span class="line">        <span class="built_in">position</span> = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 1st way: pack the new type</span></span><br><span class="line">        <span class="comment">//MPI_Pack(MPI_BOTTOM, 1, newtype, buff, psize, &amp;position, MPI_COMM_WORLD);</span></span><br><span class="line">        <span class="comment">// 2nd way: directly pack the old types</span></span><br><span class="line">        MPI_Pack(&amp;i, <span class="number">1</span>, MPI_INT, buff, psize, &amp;<span class="built_in">position</span>, MPI_COMM_WORLD);</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"Proc 0: position after 1st MPI_Pack is "</span>&lt;&lt;<span class="built_in">position</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        MPI_Pack(a, <span class="number">10</span>, MPI_DOUBLE, buff, psize, &amp;<span class="built_in">position</span>, MPI_COMM_WORLD);</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"Proc 0: position after 2nd MPI_Pack is "</span>&lt;&lt;<span class="built_in">position</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        MPI_Send(buff, psize, MPI_PACKED, <span class="number">1</span>,<span class="number">0</span>,MPI_COMM_WORLD);</span><br><span class="line">        MPI_Type_free(&amp;newtype);</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(rank==<span class="number">1</span>)&#123;</span><br><span class="line">        </span><br><span class="line">        MPI_Recv(buff, <span class="number">1000</span>, MPI_PACKED, <span class="number">0</span>,<span class="number">0</span>,MPI_COMM_WORLD, &amp;status);</span><br><span class="line">        <span class="comment">// 1000 is the size in byte</span></span><br><span class="line">        <span class="built_in">position</span> = <span class="number">0</span>;</span><br><span class="line">        MPI_Unpack(buff,<span class="number">1000</span>,&amp;<span class="built_in">position</span>,&amp;i,<span class="number">1</span>,MPI_INT,MPI_COMM_WORLD);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"Proc 1: After first unpack, the position is "</span>&lt;&lt;<span class="built_in">position</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"Proc 1: The value i is "</span>&lt;&lt;i&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        </span><br><span class="line">        MPI_Unpack(buff,<span class="number">1000</span>,&amp;<span class="built_in">position</span>,a,<span class="number">10</span>,MPI_DOUBLE, MPI_COMM_WORLD);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"Proc 1: After second unpack, the position is "</span>&lt;&lt;<span class="built_in">position</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;<span class="number">10</span>;j++)&#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">"Proc 1: a["</span>&lt;&lt;j&lt;&lt;<span class="string">"]="</span>&lt;&lt;a[j]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>
</p><p style="background-color: #000000; color: #00FF00">
Proc 0: the address of i is 140726724892152<br>
Proc 0: the address of a is 140726724892240<br>
Proc 0: position after 1st MPI_Pack is 4<br>
Proc 0: position after 2nd MPI_Pack is 84<br>
Proc 1: After first unpack, the position is 4<br>
Proc 1: The value i is 9527<br>
Proc 1: After second unpack, the position is 84<br>
Proc 1: a[0]=2.13<br>
Proc 1: a[1]=2.23<br>
Proc 1: a[2]=2.33<br>
Proc 1: a[3]=2.43<br>
Proc 1: a[4]=2.53<br>
Proc 1: a[5]=2.63<br>
Proc 1: a[6]=2.73<br>
Proc 1: a[7]=2.83<br>
Proc 1: a[8]=2.93<br>
Proc 1: a[9]=3.03<br>
</p>
<p></p>
<p><strong>Q/A: We are actors, see you next time.</strong></p>
<p>Reference:<br><a href="http://mpitutorial.com/tutorials/" target="_blank" rel="noopener">MPI Tutorial: http://mpitutorial.com/tutorials/</a><br><a href="http://mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf" target="_blank" rel="noopener">MPI Standard 3.0 http://mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf</a></p>
]]></content>
  </entry>
  <entry>
    <title>My Q&amp;A on MPI (1)</title>
    <url>/2018/04/05/mpi-1/</url>
    <content><![CDATA[<p><strong>Q: Is MPI a language?</strong><br>A: No. It is just a library in C and Fortran to facilitate the message passing among multiple processors without shared memory.</p>
<p><strong>Q: I found there are many MPI libraries. Are they different or not?</strong><br>A: Yes, they are different. We call them different implementations of MPI, e.g. MPICH, MVAPICH2, Cray MPI, Intel MPI, SGI MPI, etc. MPI is just a standard of message passing interface. The standard only specifies some interfaces, e.g. function names, parameters, types, input/output, runtime behaviour… It gives some practical suggestions for the implementors. You can refer to this official document from MPI Forum for the latest MPI 3.0.</p>
<p><strong>Q: The most common errors of a parallel program is called ‘deadlock’, what is that?</strong><br>A: Deadlock means, at some stage, the processors are waiting for each other’s response. They just hang there forever. Normally it is due to incorrect arrangement of order of send and receive calls.<br><a id="more"></a><br><strong>Q: If two cores are running one program, both call MPI_Send(), will they cause deadlock?</strong><br>A: Most likely, but not sure. MPI_Send() is the standard blocking send mode. From the MPI Standard 3.4: “In this mode, it is up to MPI to decide whether outgoing messages will be buffered.” It depends on the runtime situations, e.g. data size (key factor),  network speed, buffer available space… etc. If MPI decides to buffer the outgoing messages, it is called “buffer send mode”; otherwise, it is called “synchronous send mode”. But as a MPI user, try to do not write codes which have some deadlock risks.</p>
<p><strong>Q: I am confused about “send call return”, “send-complete”, “message passing complete” and “local/non-local”. What’s the meaning?</strong><br>A: Firstly, we say there are two types of modes. One is blocking, the other is non-blocking. Blocking send (MPI_Send())’s return means the completion of the sending process, which means the outgoing message has been stored away. Here the “stored away” has two possibilities. One possibility is it is in the transit to the receiver (synchronous, non-local). Another possibility is it is stored into some system temporary memory (buffer, local). Only the first possibility means the message has been received by the receiver.<br>For non-blocking mode (MPI_Isend()), it will always return immediately. This “return” only means the system gets the request from the sender to send messages.</p>
<p><strong>Q: The system will provides some temporary memory to store the messages automatically? Do our users need to worry about the memory leak?</strong><br>A: Yes. No. Those temporary memories are maintained by the MPI and system.</p>
<p><strong>Q: What’s the most important difference between blocking and non-blocking send?</strong><br>A: The “return” is the key. The return of blocking send means the user can modify the send buffer, but that of non-blocking send does not have that meaning. It must be accompanied with MPI_Wait or MPI_Test to obtain the send-completion.</p>
<p><strong>Q: I really do not want to let MPI to determine things. How can I use the buffer-send or synchronous-send directly?</strong><br>A: MPI_Bsend or MPI_Ssend. Especially for the Bsend, the user needs to prepare the memory by him/her-self and then provide the MPI with it for buffering purpose. Finally, the user is also responsible to release that bunch of memory to avoid any leak.</p>
<p><strong>Q: You mention “send-completion” and “send buffer is ready to modification”. Are they the same?</strong><br>A: Yes.</p>
<p><strong>Q: The message goes directly from the sender to receiver, right?</strong><br>A: No. In buffer mode, the message needs to be stored into some buffer first before going to the receiver. The buffer is either provided by the system automatically or by the user explicitly.</p>
<p><strong>Q: How big the buffer is? Is it equal to the size of the outgoing data?</strong><br>A: No. The size of the buffer is the size of outgoing data + overhead (MPI_BSEND_OVERHEAD). The overhead has the information about the message envelope. Normally, the MPI_BSEND_OVERHEAD is different in different implementations, platforms, versions. You can check it in mpi.h file. The unit is byte.</p>
<p><strong>Q: Can a processor send messages to itself?</strong><br>A: Yes, but not recommended to avoid any undefined behaviors.</p>
<p><strong>Q: If I am the receiver, after the MPI_Recv() returns, how can I double-check whether the message is correct or not.</strong><br>A: use the status obtained. Its type is MPI_Status, which contains MPI_SOURCE, MPI_TAG and MPI_Error for users to check.</p>
<p><strong>Q: Is Non-blocking necessarily asynchronous?</strong><br>A: No. The concept of blocking/non-blocking is totally different from the concept of a-synchronous.</p>
<p><strong>Q: For blocking send, which mode is the best?</strong><br>A: Hard to say, but generally MPI_Ssend(). Because it does not do any buffering definitely. Of course, the user needs to arrange the MPI_Recv() properly to minimize the overhead.</p>
<p><strong>Q: If my program is very large, which needs a lot of message passing. What’s the maximum tags supported by MPI?</strong><br>A: You can use the MPI_TAG_UB to find the maximum. From the Standard 3.0, that number is no less than 32767.</p>
<p><strong>Q: If the two processors belonging to two heterogeneous machines respectively, how can I make sure the data representation is correct in communication?</strong><br>A: The user should not worry about that except it communicating MPI_BYTE directly. From the MPI Standard, the integer, char will be maintained exactly. The floating number will be transformed into the closest one.</p>
<p><strong>Q: Would the synchronous send mode not buffer any data?</strong><br>A: No! This is a very interesting feature. The MPI implementation sometimes will make the decision for the user. I will use the MPI_Issend() to tell the difference. The code example is here:<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">"mpi.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> rank, <span class="built_in">size</span>, *sendbuf;</span><br><span class="line">  MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">  MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);</span><br><span class="line">  MPI_Comm_size(MPI_COMM_WORLD, &amp;<span class="built_in">size</span>);</span><br><span class="line">  MPI_Request s_req, r_req;</span><br><span class="line">  MPI_Status s_stat, r_stat;</span><br><span class="line">  <span class="keyword">int</span> ndata = <span class="number">100000</span>;</span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt; data;</span><br><span class="line">  data.resize(ndata);</span><br><span class="line">  <span class="keyword">if</span>(rank==<span class="number">0</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;ndata;i++)&#123;</span><br><span class="line">      data[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line">    MPI_Issend(&amp;data[<span class="number">0</span>], ndata, MPI_DOUBLE, <span class="number">1</span>, <span class="number">99</span>, MPI_COMM_WORLD, &amp;s_req);</span><br><span class="line">    data[ndata<span class="number">-1</span>]=<span class="number">9527</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"The data from proc 0 before MPI_WAIT is:"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;data[ndata<span class="number">-1</span>]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    MPI_Wait(&amp;s_req, &amp;s_stat);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"The data from proc 0 after MPI_Wait is:"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;data[ndata<span class="number">-1</span>]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    </span><br><span class="line">  &#125;<span class="keyword">else</span> <span class="keyword">if</span>(rank == <span class="number">1</span>)&#123;</span><br><span class="line">    usleep(<span class="number">3e6</span>);</span><br><span class="line">    MPI_Recv(&amp;data[<span class="number">0</span>], ndata, MPI_DOUBLE, <span class="number">0</span>, <span class="number">99</span>, MPI_COMM_WORLD, &amp;r_stat);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"The data from proc 1 is:"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;data[ndata<span class="number">-1</span>]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  MPI_Barrier(MPI_COMM_WORLD);</span><br><span class="line">  MPI_Finalize();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>
</p><p style="background-color: #000000; color: #00FF00">
The data from proc 0 before MPI_WAIT is:<br>
9527<br>
The data from proc 0 after MPI_Wait is:<br>
9527<br>
The data from proc 1 is:<br>
9527<br>
</p>
<br>After change the ndata=10:<br>
<p style="background-color: #000000; color: #00FF00">
The data from proc 0 before MPI_WAIT is:<br>
9527<br>
The data from proc 0 after MPI_Wait is:<br>
9527<br>
The data from proc 1 is:<br>
9<br>
</p>
<br>The outgoing messages were buffered into system temporary memory for small data (10 double variables) even if I use the MPI_Issend(). In this case, the modification on the send buffer will not change the data received by the receiver because it has already been buffered. For large data, MPI_Issend() determines to use synchrounous mode, so the modification will influcence the received data. At this point, I think MPI_Issend() is very similar with MPI_Isend(). (It does not strictly obey the MPI Standard?) Note: The above code is just for test purpose. Users always can not modify the send buffer before MPI_Wait().<p></p>
<p><strong>Q: Now, I change my mind. I want to use the buffer send, how to do that?</strong><br>A: See the code, especially the MPI_Pack_size, MPI_Buffer_attach and MPI_Buffer_detach. Look at the final data received by proc 1.<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">"mpi.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> rank, <span class="built_in">size</span>, *sendbuf;</span><br><span class="line">  MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">  MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);</span><br><span class="line">  MPI_Comm_size(MPI_COMM_WORLD, &amp;<span class="built_in">size</span>);</span><br><span class="line"></span><br><span class="line">  MPI_Request s_req, r_req;</span><br><span class="line">  MPI_Status s_stat, r_stat;</span><br><span class="line">  <span class="keyword">int</span> ndata = <span class="number">10000</span>;</span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt; data;</span><br><span class="line">  data.resize(ndata);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">double</span>* <span class="built_in">buffer</span>;</span><br><span class="line">  <span class="keyword">int</span> bsize, tsize;</span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="keyword">double</span>&gt; output;</span><br><span class="line">  <span class="keyword">if</span>(rank==<span class="number">0</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;ndata;i++)&#123;</span><br><span class="line">      data[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    MPI_Pack_size(ndata, MPI_DOUBLE, MPI_COMM_WORLD, &amp;bsize);</span><br><span class="line">    <span class="built_in">buffer</span> = <span class="keyword">new</span> <span class="keyword">double</span>[bsize+MPI_BSEND_OVERHEAD];</span><br><span class="line">    MPI_Buffer_attach(<span class="built_in">buffer</span>, bsize+MPI_BSEND_OVERHEAD);</span><br><span class="line">    MPI_Bsend(&amp;data[<span class="number">0</span>], ndata, MPI_DOUBLE, <span class="number">1</span>, <span class="number">99</span>, MPI_COMM_WORLD);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"The proc 0 has finished buffering."</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    usleep(<span class="number">1000000</span>);</span><br><span class="line">    data[ndata<span class="number">-1</span>]=<span class="number">9527</span>;</span><br><span class="line">    output.push_back(data[ndata<span class="number">-1</span>]);</span><br><span class="line">    MPI_Buffer_detach(&amp;<span class="built_in">buffer</span>, &amp;tsize);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"The buffer size is "</span>&lt;&lt;tsize&lt;&lt;<span class="string">"."</span>&lt;&lt;<span class="built_in">endl</span>; </span><br><span class="line">    <span class="keyword">delete</span> [] <span class="built_in">buffer</span>;</span><br><span class="line">  &#125;<span class="keyword">else</span> <span class="keyword">if</span>(rank == <span class="number">1</span>)&#123;</span><br><span class="line">    usleep(<span class="number">3e6</span>);</span><br><span class="line">    MPI_Recv(&amp;data[<span class="number">0</span>], ndata, MPI_DOUBLE, <span class="number">0</span>, <span class="number">99</span>, MPI_COMM_WORLD, &amp;r_stat);</span><br><span class="line">    output.push_back(data[ndata<span class="number">-1</span>]);</span><br><span class="line">  &#125;</span><br><span class="line">  MPI_Barrier(MPI_COMM_WORLD);</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="built_in">size</span>;i++)&#123;</span><br><span class="line">    <span class="keyword">if</span>(i==rank)&#123;</span><br><span class="line">      <span class="built_in">cout</span>&lt;&lt;<span class="string">"The output from proc "</span>&lt;&lt;i&lt;&lt;<span class="string">": "</span>&lt;&lt;output[<span class="number">0</span>]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    MPI_Barrier(MPI_COMM_WORLD);</span><br><span class="line">  &#125;</span><br><span class="line">  MPI_Finalize();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>
</p><p style="background-color: #000000; color: #00FF00">
The proc 0 has finished buffering.<br>
The buffer size is 80096.<br>
The output from proc 0: 9527<br>
The output from proc 1: 9999<br>
</p>
<br>The similar thing, the modification to the send buffer will not influence the data received by the receiver.<br><strong>Q: Is the MPI_Rsend() useful?</strong><br>A: Yes, but its usage should be only in some limited situations.<p></p>
<p>Q: Another question…<br>A: Today is too late. Let’s talk next time.</p>
<p>Reference:<br><a href="http://mpitutorial.com/tutorials/" target="_blank" rel="noopener">MPI Tutorial: http://mpitutorial.com/tutorials/</a><br><a href="http://mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf" target="_blank" rel="noopener">MPI Standard 3.0 http://mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf</a></p>
]]></content>
  </entry>
  <entry>
    <title>有关C和指针</title>
    <url>/2017/12/10/c-pointer-cn/</url>
    <content><![CDATA[<p>这篇博客有关一本C语言书《征服C指针》，作者是日本软件工程师<a href="https://www.amazon.com/Kazuya-Maebasi/e/B004LT29A0" target="_blank" rel="noopener">Maebasi Kazuya</a>（前桥和弥）。这不是一本有关C语言的完全指南，但是是一本用来厘清少量看上去很基础但是确实很重要概念的书，比如指针，数组，字符串，内存等等。作者不是像大部分教科书那样把所有的要点一一罗列，而是他逐步提出了几个让自己疑惑的问题，然后逐一解答。我觉得，对于每一位程序设计师，即便不用C语言,这是一本非常有价值，而且让人大开眼界的书，因为很多概念与语言无关。在解释某些概念时，会展示一些代码，读者可以跳转到<a href="https://www.onlinegdb.com/" target="_blank" rel="noopener">onlinegdb.com</a>进行现场的实践. 这个网站的好处是可以在线用gdb调试简单程序。</p>
<p>在正式开始之前，有3句话是本博客<strong>最想说的</strong>：<br><blockquote><p>1、当你遇到某种奇怪的语法的时候，不要试图寻找某种方式或者某个角度去理解以达到使其显得更加自然的目的，直接记住就好，因为c语言本身就是奇怪的，不自然的。<br>2、数组不等于指针。<br>3、经常听人们说“字符串常量”，但是字符串有时候还真不是常量，是变量。</p>
</blockquote><br><a id="more"></a></p>
<h2 id="1-指针"><a href="#1-指针" class="headerlink" title="1 指针"></a>1 指针</h2><ul>
<li><p>当我们谈论指针的时候，我们在谈论什么？答：不知道。<br>很多时候，我们经常听到有人说“这个指针怎么样怎么样”，但是我们需要先确定一下，指针是一个数据类型，但它不是基本数据类型(int, double, char…)，而是派生数据类型。就像其他基本数据类型的变量一样，指针数据类型的变量也是有变量名，变量的内容，以及变量在内存中存在的地址等信息。当我们谈论指针的时候，最好需要搞明白我们谈论的是指针类型的变量还是指针类型的值？这个很重要，牵扯到很多概念，比如左值、右值。</p>
</li>
<li><p>指针变量声明时，指针类型包不包含星号？答：很难说，因为有矛盾。<br>其实指针在一开始就有一个坑，那就是指针变量的声明：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>* p;</span><br></pre></td></tr></table></figure>
<p>这句代码声明了一个指向int数据类型的指针变量p, 其中“指向int的指针类型”用int*表示，也就是说int和*是整体，但是当在一行声明多个指针的时候，只能写成</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> *p1, *p2, *p3;</span><br></pre></td></tr></table></figure>
<p>这个时候*跟变量名又变成了整体，这个规定很不自然。</p>
</li>
<li><p>既然指针变量保存的是内存地址，对于64位计算机，也就是8个byte的“门牌号”，那为什么还要区分指向int的指针和指向char的指针？他们不一样吗？<br>答：不一样，因为要照顾到指针运算。<br>第一，如果在表达式中，一个指针变量前加一个*，代表解引用，也就是取出这个指针指向的数据。如果指针对指向的数据类型不作区分，那么当面对一堆0，1时，计算机不知道要读几位, 无法正确地按照格式取出数据。注意，这里面又有一个坑，那就是表达式中的*代表取出指针所指向的数据内容，跟在声明中的*的意义是不一样的。<br>第二，指针加法运算。对指针+1，意味着得到一个新的地址，这个地址可不是原地址+1，而是原来指针的地址加上被指数据类型的大小。如果不限定类型，就不知道地址要移动几位. 当然，有的人可能会质疑，因为C语言中有void*指针，并没有限定数据类型，就是一个单纯的地址，那如果+1会移动几位？加1位。为了解答，看下面的例子比如</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>  a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">char</span> b = <span class="string">'x'</span>;</span><br><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">3</span>];</span><br><span class="line"><span class="keyword">int</span>* p_a = &amp;a;</span><br><span class="line"><span class="keyword">char</span>* p_b = &amp;b;</span><br><span class="line"><span class="keyword">void</span> *p_c = &amp;a;</span><br><span class="line"><span class="keyword">int</span> (*p_array)[<span class="number">3</span>];</span><br><span class="line">p_array = &amp;<span class="built_in">array</span>;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_a   is %p.\n"</span>, p_a);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_a+1 is %p.\n"</span>, p_a+<span class="number">1</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_b   is %p.\n"</span>, p_b);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_b+1 is %p.\n"</span>, p_b+<span class="number">1</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_c   is %p.\n"</span>, p_c);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_c+1 is %p.\n"</span>, p_c+<span class="number">1</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_array   is %p.\n"</span>, p_array);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_array+1 is %p.\n"</span>, p_array+<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
The value of p_a   is 0x7ffc3122139c.<br>
The value of p_a+1 is 0x7ffc312213a0.<br>
The value of p_b   is 0x7ffc3122139b.<br>
The value of p_b+1 is 0x7ffc3122139c.<br>
The value of p_c   is 0x7ffc3122139c.<br>
The value of p_c+1 is 0x7ffc3122139d.<br>
The value of p_array   is 0x7ffc312213a0.<br>
The value of p_array+1 is 0x7ffc312213ac.<br>
</p>

<p>int指针前进了4个字节，char和void指针都前进了1个。int[3]指针前进了12个字节。有关数组的指针，也是很容易弄错的，后面会详细讲。</p>
</li>
</ul>
<h2 id="2-数组"><a href="#2-数组" class="headerlink" title="2 数组"></a>2 数组</h2><p>像int, char, double等等，都是scalar，但是数组不是，而是聚合类型(aggregate)。</p>
<ul>
<li>在读取数组是,方括号跟数组没有任何关系。在读取数组的时候p[i]仅仅是*(p+i)的语法糖，写成i[p]也是可以的<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">3</span>]=&#123;<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>&#125;;;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The array[1] is %d.\n"</span>, <span class="built_in">array</span>[<span class="number">1</span>]);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The *(array+1) is %d.\n"</span>, *(<span class="built_in">array</span>+<span class="number">1</span>));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The 1[array] is %d.\n"</span>, <span class="number">1</span>[<span class="built_in">array</span>]);</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
The array[1] is 20.<br>
The *(array+1) is 20.<br>
The 1[array] is 20.<br>
</p>

<blockquote><p>比i[array]==array[i]更重要的是不要写i[array]，这不是人类的理解方式…</p>
</blockquote>
</li>
</ul>
<h2 id="3-数组可以当作指针来使用的情况（数组不等于指针）"><a href="#3-数组可以当作指针来使用的情况（数组不等于指针）" class="headerlink" title="3 数组可以当作指针来使用的情况（数组不等于指针）"></a>3 数组可以当作指针来使用的情况（数组不等于指针）</h2><p>虽然数组是聚合类型,而指针是标量, 但是他们有很多相似之处. 经常会发现数组跟指针很像，这是有道理的。</p>
<ul>
<li>当我们在谈论“数组等于指针”的时候，我们在谈论什么？答：数组变量名其实就是“指向该数组第一个元素的地址”的指针。<br>比如在声明函数形参的时候，[ ]与*等价。<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">function</span><span class="params">(<span class="keyword">int</span> *p)</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">function</span><span class="params">(<span class="keyword">int</span> p[])</span></span></span><br></pre></td></tr></table></figure>
但是数组变量名并不是指向自己(数组)的指针, 只有数组名前面加&amp;，才是指向该数组的指针，如下例:<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">3</span>];</span><br><span class="line"><span class="keyword">int</span> *p_1;</span><br><span class="line"><span class="keyword">int</span> (*p_2)[<span class="number">3</span>];</span><br><span class="line">p_1 = <span class="built_in">array</span>; <span class="comment">//correct</span></span><br><span class="line">p_1 = &amp;<span class="built_in">array</span>; <span class="comment">// wrong, assign a int*[3] to int*</span></span><br><span class="line">p_2 = <span class="built_in">array</span>; <span class="comment">// wrong, assign a int* to int*[3]</span></span><br><span class="line">p_2 = &amp;<span class="built_in">array</span>; <span class="comment">// correct</span></span><br></pre></td></tr></table></figure>
注：由于某些原因，onlinegdb.com居然没有报错，但是在其他任何平台都会报错。也就是说数组跟指针有如下关系：<blockquote><p>1 在<strong>表达式</strong>中, <strong>当作右值使用时</strong>，数组名其实就是指向其第一个元素的指针（什么叫右值？看书就明白了。）<br>2 数组名前加&amp;是指向数组这个整体的指针，此时这个指针指向的已经不再是基本类型，而是聚合类型</p>
</blockquote>
</li>
</ul>
<h2 id="4-数组不等于指针"><a href="#4-数组不等于指针" class="headerlink" title="4 数组不等于指针"></a>4 数组不等于指针</h2><ul>
<li><p>有没有一个好的例子来证明这句话？答：有，看所占空间的大小。<br>我们知道，数组的大小应该是元素的个数乘以每个元素的大小，但是指针的大小在某台固定的机器上是一样的，比如32位机器应该是4个byte，64位机器应该是8个byte，例子证明</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a;</span><br><span class="line"><span class="keyword">int</span> *p;</span><br><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> *array_p = <span class="built_in">array</span>;</span><br><span class="line"><span class="keyword">int</span> *array_of_pointer[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> array2d[<span class="number">2</span>][<span class="number">3</span>];</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of a is %d.\n"</span>, <span class="keyword">sizeof</span>(a));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of p is %d.\n"</span>, <span class="keyword">sizeof</span>(p));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of array is %d.\n"</span>, <span class="keyword">sizeof</span>(<span class="built_in">array</span>));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of array_p is %d.\n"</span>, <span class="keyword">sizeof</span>(array_p));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of array_of_pointer is %d.\n"</span>, <span class="keyword">sizeof</span>(array_of_pointer));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of array2d is %d.\n"</span>, <span class="keyword">sizeof</span>(array2d));</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
The size of a is 4.<br>
The size of p is 8.<br>
The size of array is 40.<br>
The size of array_p is 8.<br>
The size of array_of_pointer is 80.<br>
The size of array2d is 24.<br>
</p>

<p>发现int占4个字节，地址(64位计算机)占8个字节，array数组占10x4=40个字节，array_of_pointer占10x8=80个字节，array2d占2x3x4=24个字节</p>
</li>
<li><p>除了上面这个大小的问题，还有哪些不同？答：至少在字符串方面很不一样。<br>对于字符串，也有数组与指针的不同。字符串的本质是char的数组，而不是指向char的指针，下面代码可以验证这一点：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">printf</span>(<span class="string">"The size is %d.\n"</span>, <span class="keyword">sizeof</span>(<span class="string">"Felix"</span>));</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
The size is 6.
</p>  

<p>大小是6，因为字符串在末尾加了’\0’。如果字符串本质是指向char的指针，那大小应该是8。<br>但是接下来的问题非常confusing</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> *str</span><br><span class="line">str=”abc”; </span><br></pre></td></tr></table></figure>
<p>char的数组在表达式中解读为指针，所以=左右两边都是指针，这是一个普通的指针的赋值，是合法的。<br>但是</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> str[<span class="number">4</span>];</span><br><span class="line">str = “abc”;</span><br></pre></td></tr></table></figure>
<p>是非法的，因为str是数组，当它出现在=左边的时候，是当作左值使用，只有作右值时才可以看成指针，此时str不能看作指针，所以无法接受”abc”的赋值。但是，一个例外就是初始化！初始化不同于普通的赋值操作</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> str[<span class="number">4</span>] = “abc”；</span><br></pre></td></tr></table></figure>
<p>是合法的。<br>也就是说，目前我们掌握了两种声明字符串的方法，一种是用指针，一种是用数组。又回到了我们的中心问题：数组跟指针有啥区别？这两种方法有什么不同吗？答案就是：一个是字符串常量，不能修改，一个是字符串变量，可以修改。因为这两种方式定义出来的字符串在内存中存放的位置完全不同。如下</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> *str1 = <span class="string">"abc"</span>;</span><br><span class="line">str1[<span class="number">0</span>] = <span class="string">'w'</span>;</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
Segmentation fault.
</p>

<p>但是，如果用数组来保存字符串，就会变得可以修改。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> *str1 = <span class="string">"abc"</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The address of \"abc\" is %p.\n"</span>, str1);</span><br><span class="line"></span><br><span class="line"><span class="keyword">char</span> str2[] = <span class="string">"def"</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The address of \"def\" is %p.\n"</span>, str2);</span><br><span class="line">str2[<span class="number">0</span>] = <span class="string">'w'</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The str2 is %s.\n"</span>, str2);</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
The address of "abc" is 0x400ab4.<br>
The address of "def" is 0x7ffc6960c770.<br>
The str2 is wef.<br>
</p>

<p>从上面的例子发现，”abc”的地址很小，而”def”的地址很大，这其实就预示着它们保存在了内存中的不同区域，一个仅仅只读，另一个却可以修改。那为什么地址小就无法修改，地址大就可以修改？请看下一段。</p>
</li>
</ul>
<h2 id="5-内存相关"><a href="#5-内存相关" class="headerlink" title="5 内存相关"></a>5 内存相关</h2><p>事实上，在c语言执行的过程中，信息需要保存在内存中，包括函数，调用信息，各种变量等等，它们的存放顺序是<br><img src="/images/memory_cn.png" alt="Memory_overview"><br>字符串常量被放在了跟函数自身相同的区域，也就是不能修改的。上面的例子中，当用指针来接受一个字符串的赋值之前，事实上该字符串已经以常量的形式保存在了跟函数自身相同的内存区域里，而通过数组来初始化字符串的时候，该字符串保存在了自动变量的区域，所以是可以修改的。</p>
<p>想看就请购买吧，如果不在中国，也有kindle电子版：(<a href="http://www.ituring.com.cn/book/1036" target="_blank" rel="noopener">去买书</a>)</p>
]]></content>
  </entry>
  <entry>
    <title>About C and Pointer</title>
    <url>/2017/12/08/c-pointer-20171209/</url>
    <content><![CDATA[<p>This blog is about the Chinese translation of a good C language book named “<a href="https://book.douban.com/subject/21317828/" target="_blank" rel="noopener">征服c指针</a>“ by a Japanese programmer <a href="https://www.amazon.com/Kazuya-Maebasi/e/B004LT29A0" target="_blank" rel="noopener">Maebasi Kazuya</a>. I found it is far from a complete guide for C, but a very good book clarifying some seemly basic but extremely important concepts, e.g. array, pointer, string, memory etc. The author didn’t just list the knowledge one by one in the style which most textbooks did. Instead, he divided into several problems which made him feel confused and then give the solutions. It is a very valuable supplementary and eye-opening book for every programmer. In this blog, I will show some code to illustrate some concepts. Readers can go to <a href="https://www.onlinegdb.com/" target="_blank" rel="noopener">onlinegdb.com</a> to practice, which allows users to even debug online.</p>
<p>Before we start, I have <strong>3 most important points</strong>:<br><blockquote><p>1 When you encounter some strange syntax in C, do not try to find some ways to explain to make the C more natural. Just remember that strange syntax, because C itself is strange indeed.<br>2 Array is not equivalent to pointer.<br>3 Many people talk about “constant string”, but sometimes, the string can be modified.</p>
</blockquote><br><a id="more"></a></p>
<h2 id="1-Pointer"><a href="#1-Pointer" class="headerlink" title="1 Pointer"></a>1 Pointer</h2><ul>
<li><p>When we talk about pointers, what do we talk? Answer: I don’t know.<br>In many cases, we hear about many people say “This pointer is blablabla”, but we should confirm that pointer is a data type in C. Unlike the basic data type like int, char, double, etc, pointer is a derived data type. A variable with pointer type also has its name, value, location in memory and so on. It’s better to clarify what we are talking about, variable? value? or others? This is very important, because it has to do with many concepts, like left value and right value (refer the book to learn).</p>
</li>
<li><p>In declaration of a pointer variable, does the pointer type consist of the asterisk sign? Answer: Hard to say. It depends.<br>In fact, pointer has an issue at the beginning:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>* p;</span><br></pre></td></tr></table></figure>
<p>The above line declares a pointer variable p pointing to int. “Pointer pointing to a int” is represented by int*. It means the int* acts as a whole thing. However, when you want to declare multiple pointers in one line, you have to deplicate the asterisk sign for each pointer variable.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> *p1, *p2, *p3;</span><br></pre></td></tr></table></figure>
<p>In this case, the * and variable name act as a whole thing. This syntax is not natural.</p>
</li>
<li><p>Because pointer stores the address in memory (8 bytes for 64-bit OS), why should we distinguish a pointer pointing to int and another pointer pointing to char? Are they different? Answer: For pointer operation.<br>First of all, in an expression, if a sterisk is added before a pointer, it means to retrieve the value of what it points to. If we do not tell how many bytes this pointer points to, it can not retrieve the value correctly when facing those 0 and 1 in memory.<br>Secondly, if we plus 1 to a pointer, we will get a new address. This new address is not simply add 1 to the address value. The size it will increase is equal to the size of the data type which it points to. Someone may ask how about void*? It does not assign any specific data type, how many bytes it will increase when +1? My test is it will increase 1 byte. See below</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>  a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">char</span> b = <span class="string">'x'</span>;</span><br><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">3</span>];</span><br><span class="line"><span class="keyword">int</span>* p_a = &amp;a;</span><br><span class="line"><span class="keyword">char</span>* p_b = &amp;b;</span><br><span class="line"><span class="keyword">void</span> *p_c = &amp;a;</span><br><span class="line"><span class="keyword">int</span> (*p_array)[<span class="number">3</span>];</span><br><span class="line">p_array = &amp;<span class="built_in">array</span>;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_a   is %p.\n"</span>, p_a);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_a+1 is %p.\n"</span>, p_a+<span class="number">1</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_b   is %p.\n"</span>, p_b);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_b+1 is %p.\n"</span>, p_b+<span class="number">1</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_c   is %p.\n"</span>, p_c);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_c+1 is %p.\n"</span>, p_c+<span class="number">1</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_array   is %p.\n"</span>, p_array);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The value of p_array+1 is %p.\n"</span>, p_array+<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
The value of p_a   is 0x7ffc3122139c.<br>
The value of p_a+1 is 0x7ffc312213a0.<br>
The value of p_b   is 0x7ffc3122139b.<br>
The value of p_b+1 is 0x7ffc3122139c.<br>
The value of p_c   is 0x7ffc3122139c.<br>
The value of p_c+1 is 0x7ffc3122139d.<br>
The value of p_array   is 0x7ffc312213a0.<br>
The value of p_array+1 is 0x7ffc312213ac.<br>
</p>

<p>The pointer to int increases 4 bytes, while the pointers to char and void increase 1 byte respectively. The pointer to int[3] increases 12 bytes, because the size of int[3] is equal to 12, which will be explained later.</p>
</li>
</ul>
<h2 id="2-Array"><a href="#2-Array" class="headerlink" title="2 Array"></a>2 Array</h2><p>Like int, char, double, etc, they are scalar and basic type, but array is not. Array is an aggregate and derived data type.</p>
<ul>
<li>When reading in arrays, the square brackets have nothing to do with the array concept. It is just a syntax sugar to pointer. p[i] is just a syntax sugar of *(p+i), which can also be written as *(i+p) or i[p].<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">3</span>]=&#123;<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>&#125;;;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The array[1] is %d.\n"</span>, <span class="built_in">array</span>[<span class="number">1</span>]);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The *(array+1) is %d.\n"</span>, *(<span class="built_in">array</span>+<span class="number">1</span>));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The 1[array] is %d.\n"</span>, <span class="number">1</span>[<span class="built_in">array</span>]);</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
The array[1] is 20.<br>
The *(array+1) is 20.<br>
The 1[array] is 20.<br>
</p>

<blockquote><p>What is more important than i[array]==array[i] is do not write this line.</p>
</blockquote>
</li>
</ul>
<h2 id="3-Array-is-used-as-pointer-in-some-cases（array-is-not-pointer）"><a href="#3-Array-is-used-as-pointer-in-some-cases（array-is-not-pointer）" class="headerlink" title="3 Array is used as pointer in some cases（array is not pointer）"></a>3 Array is used as pointer in some cases（array is not pointer）</h2><p>Although array is aggregate, while pointer is a scalar, but in many cases, they are pretty similar.</p>
<ul>
<li>When we talk about “Array is equal to pointer”, what do we talk? Answer: The name of the array is actually the pointer pointing to it’s first element in some situations.</li>
</ul>
<p>For example, in the dummy parameters of a function, [ ] is equivalent to *.<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">function</span><span class="params">(<span class="keyword">int</span> *p)</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">function</span><span class="params">(<span class="keyword">int</span> p[])</span></span></span><br></pre></td></tr></table></figure><br>If you want to get a pointer pointing to the entire array, we need to use &amp;array, see below<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">3</span>];</span><br><span class="line"><span class="keyword">int</span> *p_1;</span><br><span class="line"><span class="keyword">int</span> (*p_2)[<span class="number">3</span>];</span><br><span class="line">p_1 = <span class="built_in">array</span>; <span class="comment">//correct</span></span><br><span class="line">p_1 = &amp;<span class="built_in">array</span>; <span class="comment">// wrong, assign a int*[3] to int*</span></span><br><span class="line">p_2 = <span class="built_in">array</span>; <span class="comment">// wrong, assign a int* to int*[3]</span></span><br><span class="line">p_2 = &amp;<span class="built_in">array</span>; <span class="comment">// correct</span></span><br></pre></td></tr></table></figure><br>Note： for some unknown reasons，onlinegdb.com does not report any errors for the above code. But all of other compilers will report the errors. Therefore, the relationship between array and pointer is<br><blockquote><p>1 In <strong>expression</strong>, <strong>used as right value</strong>, the name of the array is just a pointer pointing to its first element. (What is right value? Please refer to the book)<br>2 If we put &amp; before the name of the array, it becomes a pointer pointing to the entire array.</p>
</blockquote></p>
<h2 id="4-Array-is-not-equal-to-pointer"><a href="#4-Array-is-not-equal-to-pointer" class="headerlink" title="4 Array is not equal to pointer"></a>4 Array is not equal to pointer</h2><ul>
<li><p>Is any good example for this? Answer: Yes, see the space it occupies.<br>We all know, the size of array is number of elements multiply the size of its each element. However, the size of pointer is fixed for a specific machine. For 32-bit machine, it is 4 bytes, while for 64-bit, it is 8 bytes. See below</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a;</span><br><span class="line"><span class="keyword">int</span> *p;</span><br><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> *array_p = <span class="built_in">array</span>;</span><br><span class="line"><span class="keyword">int</span> *array_of_pointer[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> array2d[<span class="number">2</span>][<span class="number">3</span>];</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of a is %d.\n"</span>, <span class="keyword">sizeof</span>(a));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of p is %d.\n"</span>, <span class="keyword">sizeof</span>(p));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of array is %d.\n"</span>, <span class="keyword">sizeof</span>(<span class="built_in">array</span>));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of array_p is %d.\n"</span>, <span class="keyword">sizeof</span>(array_p));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of array_of_pointer is %d.\n"</span>, <span class="keyword">sizeof</span>(array_of_pointer));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The size of array2d is %d.\n"</span>, <span class="keyword">sizeof</span>(array2d));</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
The size of a is 4.<br>
The size of p is 8.<br>
The size of array is 40.<br>
The size of array_p is 8.<br>
The size of array_of_pointer is 80.<br>
The size of array2d is 24.<br>
</p>

<p>int occupies 4 bytes，address occupies (64-bit machine) 8 bytes，array occupies 10<em>4=40 bytes, array_of_pointer occupies 10</em>8=80 bytes, and the 2D array occupies 2<em>3</em>4=24 bytes.</p>
</li>
<li><p>Except the above case, any other difference? Answer: At least for string, there are much difference also.<br>The essence of string is array of char, instead of pointer pointing to char. See below:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">printf</span>(<span class="string">"The size is %d.\n"</span>, <span class="keyword">sizeof</span>(<span class="string">"Felix"</span>));</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
The size is 6.
</p>  

<p>The size if 6, because it adds a ‘\0’ at the tail. If string is a pointer, the size should be 8.<br>However, the following issue is extremely confusing!</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> *str</span><br><span class="line">str=”abc”; </span><br></pre></td></tr></table></figure>
<p>The array of char acts as a pointer in the expression, so both sides are pointers, it is legal.<br>But</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> str[<span class="number">4</span>];</span><br><span class="line">str = “abc”;</span><br></pre></td></tr></table></figure>
<p>is illegal! Because str is array, when it appears on the left side, it can not be used as a right value, so can not be treated as a pointer, so can not receive the assignment from “abc”. HOWEVER, there is another exception. It is the initialization of array by a string.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> str[<span class="number">4</span>] = “abc”；</span><br></pre></td></tr></table></figure>
<p>is legal.<br>Up to now, we have grasped 2 ways to deal with string. One is using pointer, and the other is using array. It goes back to our initial question: what’s the difference? Answer: One is a constant, the other is a variable, because their locations in memory are different. See below:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> *str1 = <span class="string">"abc"</span>;</span><br><span class="line">str1[<span class="number">0</span>] = <span class="string">'w'</span>;</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
Segmentation fault.
</p>

<p>The above string can not be modifed, because it is a constant. However, in following case, the string can be modified</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> *str1 = <span class="string">"abc"</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The address of \"abc\" is %p.\n"</span>, str1);</span><br><span class="line"></span><br><span class="line"><span class="keyword">char</span> str2[] = <span class="string">"def"</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The address of \"def\" is %p.\n"</span>, str2);</span><br><span class="line">str2[<span class="number">0</span>] = <span class="string">'w'</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"The str2 is %s.\n"</span>, str2);</span><br></pre></td></tr></table></figure>

<p style="background-color: #000000; color: #00FF00">
The address of "abc" is 0x400ab4.<br>
The address of "def" is 0x7ffc6960c770.<br>
The str2 is wef.<br>
</p>

<p>From the above output, we find the address of “abc” is very small, but that of “def” is very large, indicating that they are stored at different places in the memory. The “abc” is read-only, while the “def” can be modifed. Next question is why the small address is read-only, but large address can be modified? See the next section.</p>
</li>
</ul>
<h2 id="5-Memory"><a href="#5-Memory" class="headerlink" title="5 Memory"></a>5 Memory</h2><p>In fact, in the process of a C program, the information needs to be saved in memory: function, calls, variables and so on. Their order is<br><img src="/images/memory_en.png" alt="Memory_overview"><br>The constant string is placed in the same area with the function, which is read-only. In the example in Section 4, when a pointer is used to be receive a string, a constant string has been save in to the read-only area before that. However, when an array is used to receieve a string, in fact, it is just a assignment using several ‘char’ to fill in the places which the array occupies.</p>
<p>If you want to read, please go to (Kindle &amp; paperback)(<a href="http://www.ituring.com.cn/book/1036" target="_blank" rel="noopener">Buy the book!</a>)</p>
]]></content>
  </entry>
  <entry>
    <title>CFD 2030: Optimistic or Pessimistic?</title>
    <url>/2017/06/24/CFD-2030-Optimistic-or-Pessimistic-1/</url>
    <content><![CDATA[<p>On June 5-9 2017, I participated in the AIAA Aviation 2017 Forum, which is really amazing. Thousands of scholars/scientists/engineers from all over the world came together to Denver, CO to present their research and also share their opinions. The topics cover every aspects of the aviation science and technology. The most exciting and open-minded topic is to foresee the future of CFD and how to achieve it. In university, I always think that the CFD is already in somewhat mature status, we just need to invent some new parts to replace with the corresponding old parts in the entire CFD ‘building’. However, after I read the paper by P.R.Spalart and V.Venkarakrishnan <a href="https://www.cambridge.org/core/journals/aeronautical-journal/article/on-the-role-and-challenges-of-cfd-in-the-aerospace-industry/AB70FEF00301B20648F5B0627893B787" target="_blank" rel="noopener">[1]</a>, I become more objective and calm. It says “We perceive a danger of <strong>overconfidence</strong> and under-competence in CFD” and “We believe the community must find a <strong>balance between enthusiasm and rigor</strong>”. I realize that there are still tons of obstacles in front of us to overcome. The role of CFD in service is still very limited. </p>
<a id="more"></a>
<p>In fact the original prediction is from the <em>CFD vision 2030</em> <a href="https://ntrs.nasa.gov/search.jsp?R=20140003093" target="_blank" rel="noopener">[2]</a>. It points out this attracting roadmap of CFD</p>
<p><img src="/images/roadmap.jpg" alt="Roadmap_of_CFD"></p>
<p>I will merge the ideas from some related papers and presentations below:</p>
<h2 id="Investment"><a href="#Investment" class="headerlink" title="Investment"></a>Investment</h2><ul>
<li>Investment has been declined much in the last decade</li>
<li>Safety is the most important factor, so the penetration of CFD is gradual</li>
<li>The initial cost of CFD can be lower than the wind-tunnel test, but if hundreds of conditions are needed to be measured, the cost comparison switches</li>
</ul>
<h2 id="HPC-hardware"><a href="#HPC-hardware" class="headerlink" title="HPC hardware"></a>HPC hardware</h2><ul>
<li>HPC hardware has rapid progress (parallelism and heterogeneous architectures, multiple processors/accelerators). </li>
<li>Some other novel technologies are emerging, line quantum computing, superconducting logic, low-power memory, massively parallel molecular computing, on-chip optics, 3D memory and so on. On 2030, we may get 30 exaFLOPS on the top supercomputers. However, we have the following impediments:<ul>
<li>Power consumption</li>
<li>To facilitate CFD development, we need higher level of software extraction in terms of OS, compiler, I/O lib and so on</li>
<li>Call for advanced programming environments, which need proper level of abstraction. The most often headache for me is to handle the libraries compatibility when compiling my code on different supercomputers</li>
<li>Robust CFD code scalability. I think the high order CFD methods have big advantage on this issue because of its compactness.</li>
<li>Lack of scalable CFD pre- and post-processing methods. On the frontend, we need geometry representation and mesh generation. On the backend, we need visualization, database generation and general knowledge extraction</li>
<li>Lack of access to HPC resources in development level.</li>
<li>Before 2012, the rate of growth of computing capability is of the order of a factor of 3.8 every two years. However, after 2012, it is only a factor of 1.8 every two years, which has 57% dropdown. In post-Moore’s law era, the “free” progress is <strong>over-estimated</strong></li>
</ul>
</li>
</ul>
<h2 id="Physical-modelling"><a href="#Physical-modelling" class="headerlink" title="Physical modelling"></a>Physical modelling</h2><ul>
<li>RANS is not enough to accurately and reliably predict turbulent flows with separation. The pre-separation physics is still provided by RANS models, which has been stagnant for 20 years. </li>
<li>LES is impractical in the foreseeable future. </li>
<li>Hybrid RANS-LES and wall-modelled LES are the best promising. The LES for predicting complex turbulent-separated flows and the RANS region will be minimized for efficiency</li>
<li>Accuracy and convergence issues of the models<ul>
<li>Converged solution? There are no consistent measurements for measuring convergence. The uniform refinement is far from satisfactory when doing grid convergence study.</li>
<li>Even converged, There are multiple solutions, so which one reflects reality?</li>
<li>The real-world experiments’ data have not been conveniently and effectively exploited to improve turbulence study</li>
</ul>
</li>
<li>other physical model: transition, combustion, renormalization group theory, systematic upscaling….</li>
<li>Lack of explicit collaboration among turbulence researchers all over the world. I think more and more common interfaces should be setup to make the communication and collaboration more natural. Education should play a role into this part.</li>
<li>The treatment of turbulence will not be a solved problem in the 21st century. However, <strong>TILDA</strong><a href="https://www.grc.nasa.gov/hiocfd/" target="_blank" rel="noopener">[3]</a> thinks this conclusion is based on classic 2nd order schemes, we have many other novel techniques: High order methods, GPU, multilevel, multiscale, IMEX…</li>
</ul>
<h2 id="Mesh-generation"><a href="#Mesh-generation" class="headerlink" title="Mesh generation"></a>Mesh generation</h2><ul>
<li>Mesh generation and grid adaptivity are still the bottleneck in CFD workflow and very little investment</li>
<li>Even the geometry representation is not good enough for CFD</li>
<li>Solution adaptive refinement of grid is necessary to get grid-converged results</li>
<li>Self-gridding is essential for CFD, but currently immature.</li>
<li>For high order method, the accuracy of geometry &amp; surface and volume gridding technique is immature</li>
</ul>
<h2 id="Algorithmic-improvements"><a href="#Algorithmic-improvements" class="headerlink" title="Algorithmic improvements"></a>Algorithmic improvements</h2><ul>
<li>The alogrithms (discretizations, solvers) act as the same important role as the computer hardware. To exploit the rapidly evolving HPC hardware, algorithmic developments will be essential</li>
<li>Higher order methods may utilize the latest HPC hardware more efficiently, but robustness and cost considerations remain</li>
<li>For 3D RANS unsteady flow, the use of error estimation and uncertainty quantification is limited. This issue needs more researchers from other related fields to walk into and leverage those technologies for aerospace applications. For longer expectation, the statistical approaches such as Bayesian techniques can be applied</li>
<li>So many different kinds of CFD methods have no clear winners and losers up to now. I think this problem needs more fair and systematic comparisons between different methods, which is exactly one part of what the High Order CFD Methods Workshop is doing.</li>
</ul>
<h2 id="Knowledge-extraction"><a href="#Knowledge-extraction" class="headerlink" title="Knowledge extraction"></a>Knowledge extraction</h2><ul>
<li>Exploiting the big data from large-scale simulations is still in infancy</li>
<li>We can not effectively use a single high fidelity CFD simulation, even the visualization for high order simulations is lacking. I also think most data of CFD is wasted. I generate several TB CFD data, which can only lay on my external hard drive</li>
<li>Merging the high fidelity CFD simulations with other aerodynamic data is also required for efficient CFD</li>
</ul>
<h2 id="Multidisciplinary-simulations"><a href="#Multidisciplinary-simulations" class="headerlink" title="Multidisciplinary simulations"></a>Multidisciplinary simulations</h2><ul>
<li>For both analysis and design optimization purposes in multidisciplinary simulations, the robustness and automation of each component is required</li>
<li>Integrate with other disciplines like acoustics, structures, heat transfer, reacting flow, radiation, dynamics and control and so on</li>
</ul>
<p>Although there are some different opinions towards the future status, which is the beauty of science I believe. From a big overview, all scientists agree well with the future directions which should be concentrated on more. It is very hard to predict the future exactly, especially in this rapidly changing era. The following figure from <em>Why the West Rules-for Now</em> by lan Morris shows the human development index in the recent 10,000 years[4]. Since the Watt steam engine was introduced, the human social development index is speeding up extremely. So, we can image a similar figure for CFD. I personally think we still live in before 1775, so what will be the Watt steam engine for “CFD development index”? Everyone may have some candidates in minds. For me, one candidate is quantum computing and another candidate is mature high order FR/CPR method (Flux Reconstruction/Correction Procedure via Reconstruction). Luckily, I am extending the latter one.</p>
<p><img src="/images/humanindex.png" alt="Human_social_development_index"></p>
<p>From <em>The Second Machine Age</em> [5], the digital technology has exponential evolving property. The HPC will continue to contribute exponentially to our CFD, but CFD is not entirely a digital technology, because the air, water as well as our blood are not that different from humans living in 10,000 years ago. Although CFD can not get exponential speedup, I think CFD is a bridge connecting the physical and the digital world. As a PhD student in this area, being objective, honest and passionate is the most important. To get those many achievements mentioned above, I hope much more students/scholars could enter into or at least pay close attention on computational science field (e.g. CFD). With more and more talents, I think we can find the “Watt engine for CFD” in the near future. In a word, I am very impressive in this successful conference and eager to participate in the next one.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References:"></a>References:</h2><p>[1] Spalart, P.R. and Venkatakrishnan, V., 2016. On the role and challenges of CFD in the aerospace industry. The Aeronautical Journal, 120(1223), pp.209-232.<br>[2] Slotnick, J., Khodadoust, A., Alonso, J., Darmofal, D., Gropp, W., Lurie, E. and Mavriplis, D., 2014. CFD vision 2030 study: a path to revolutionary computational aerosciences.<br>[3] TILDA: Towards Industry LES/DNS in Aeronautics Paving the Way for Future Accurate CFD 2017. Presented by Charles Hirsch on AIAA-AVIATION 2017 Special Session.<br>[4] Morris, I., 2010. Why the west rules-for now: The patterns of history and what they reveal about the future. P142.<br>[5] Brynjolfsson, E. and McAfee, A., 2014. The second machine age: Work, progress, and prosperity in a time of brilliant technologies. WW Norton &amp; Company.</p>
]]></content>
  </entry>
</search>
